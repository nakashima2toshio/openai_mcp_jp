# mcp_elasticsearch.py - MCPçµŒç”±ã§è‡ªç„¶è¨€èªã§Elasticsearchã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹Streamlitã‚¢ãƒ—ãƒª
# streamlit run mcp_elasticsearch.py --server.port=8503
# å‰æ: Elasticsearch MCPã‚µãƒ¼ãƒãƒ¼ãŒãƒãƒ¼ãƒˆ8002ã§èµ·å‹•ã—ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™

import streamlit as st
import os
import pandas as pd
import json
import time
from typing import Dict, Any, List, Optional, Tuple
from dotenv import load_dotenv
import plotly.express as px
import plotly.graph_objects as go

# Elasticsearchã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆé–¢é€£
try:
    from elasticsearch import Elasticsearch
    from elasticsearch.exceptions import ConnectionError, RequestError
    ELASTICSEARCH_AVAILABLE = True
except ImportError:
    ELASTICSEARCH_AVAILABLE = False
    st.error("Elasticsearchã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒå¿…è¦ã§ã™: pip install elasticsearch")

# ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from helper_api import OpenAIClient, MessageManager, config, logger
from helper_mcp import MCPSessionManager
from helper_st import UIHelper


class MCPElasticsearchManager:
    """MCPå¯¾å¿œElasticsearchãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¹ãƒˆã‚¢æ“ä½œç®¡ç† (ãƒ‡ãƒ¢ç”¨ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ¼ãƒ‰)"""
    
    def __init__(self, mcp_server_url: str = "http://localhost:8002/mcp", elasticsearch_url: str = None):
        self.mcp_server_url = mcp_server_url
        self.elasticsearch_url = elasticsearch_url or os.getenv('ELASTIC_URL', 'http://localhost:9200')
        self.indices_info = None
        self._cached_indices_info = None
        self._es_client = None
        
        if ELASTICSEARCH_AVAILABLE:
            try:
                self._es_client = Elasticsearch(
                    [self.elasticsearch_url],
                    headers={"Accept": "application/vnd.elasticsearch+json;compatible-with=8"}
                )
            except Exception as e:
                logger.error(f"Elasticsearch client initialization error: {e}")
    
    def get_indices_info(self) -> Dict[str, Any]:
        """MCPã‚µãƒ¼ãƒãƒ¼çµŒç”±ã§Elasticsearchã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æƒ…å ±ã‚’å–å¾—"""
        if self._cached_indices_info is not None:
            return self._cached_indices_info
            
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æƒ…å ±ï¼ˆElasticsearchåˆæœŸåŒ–ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ï¼‰
        default_indices = {
            "blog_articles": {
                "description": "ãƒ–ãƒ­ã‚°è¨˜äº‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹",
                "fields": {
                    "title": "text",
                    "content": "text", 
                    "category": "keyword",
                    "author": "keyword",
                    "published_date": "date",
                    "view_count": "integer",
                    "tags": "keyword"
                },
                "sample_count": 5,
                "analyzer": "standard"
            },
            "products": {
                "description": "å•†å“æƒ…å ±ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹",
                "fields": {
                    "name": "text",
                    "description": "text",
                    "category": "keyword",
                    "price": "integer",
                    "brand": "keyword"
                },
                "sample_count": 10,
                "analyzer": "standard"
            },
            "knowledge_base": {
                "description": "çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹",
                "fields": {
                    "topic": "text",
                    "content": "text",
                    "tags": "keyword",
                    "difficulty_level": "keyword",
                    "source": "keyword"
                },
                "sample_count": 50,
                "analyzer": "standard"
            }
        }
        
        # å®Ÿéš›ã®Elasticsearchã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã—ã¦ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æƒ…å ±ã‚’å–å¾—ï¼ˆå¯èƒ½ãªå ´åˆï¼‰
        # ES9äº’æ›æ€§å•é¡Œã®ãŸã‚ä¸€æ™‚çš„ã«ã‚¹ã‚­ãƒƒãƒ—ã€ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
        if False and self._es_client:
            try:
                actual_indices = {}
                # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä¸€è¦§ã‚’å–å¾—
                indices_response = self._es_client.indices.get_alias()
                
                for index_name in indices_response.keys():
                    if not index_name.startswith('.'):  # ã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’é™¤å¤–
                        try:
                            # ãƒãƒƒãƒ”ãƒ³ã‚°æƒ…å ±ã‚’å–å¾—
                            mapping_response = self._es_client.indices.get_mapping(index=index_name)
                            mapping = mapping_response.get(index_name, {}).get('mappings', {})
                            properties = mapping.get('properties', {})
                            
                            # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°ã‚’å–å¾—
                            count_response = self._es_client.count(index=index_name)
                            doc_count = count_response.get('count', 0)
                            
                            fields_info = {}
                            for field_name, field_config in properties.items():
                                fields_info[field_name] = field_config.get('type', 'unknown')
                            
                            actual_indices[index_name] = {
                                "description": f"{index_name}ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹",
                                "fields": fields_info,
                                "sample_count": doc_count,
                                "analyzer": "standard"
                            }
                            
                        except Exception as e:
                            logger.warning(f"Could not get details for index {index_name}: {e}")
                
                if actual_indices:
                    self._cached_indices_info = actual_indices
                    return actual_indices
                    
            except Exception as e:
                logger.warning(f"Could not fetch actual Elasticsearch indices: {e}")
        
        self._cached_indices_info = default_indices
        return default_indices


class MCPDocumentQueryProcessor:
    """MCPçµŒç”±ã§è‡ªç„¶è¨€èªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¯ã‚¨ãƒªã‚’å‡¦ç†ã™ã‚‹ãƒ—ãƒ­ã‚»ãƒƒã‚µ"""
    
    def __init__(self, openai_client: OpenAIClient, elasticsearch_manager: MCPElasticsearchManager):
        self.openai_client = openai_client
        self.elasticsearch_manager = elasticsearch_manager
        self.indices_info = elasticsearch_manager.get_indices_info()
    
    def build_mcp_prompt(self, user_query: str) -> List[Dict[str, str]]:
        """MCPçµŒç”±ã§ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        indices_text = self._format_indices_info()
        
        system_prompt = f"""ã‚ãªãŸã¯Elasticsearch MCPã‚µãƒ¼ãƒãƒ¼ã¨é€£æºã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è‡ªç„¶è¨€èªã«ã‚ˆã‚‹è³ªå•ã‚’ç†è§£ã—ã€é©åˆ‡ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢æ“ä½œã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

ã€Elasticsearchã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã€‘
{indices_text}

ã€MCPæ“ä½œã«ã¤ã„ã¦ã€‘
- Elasticsearch MCPã‚µãƒ¼ãƒãƒ¼ãŒåˆ©ç”¨å¯èƒ½ã§ã™
- å…¨æ–‡æ¤œç´¢ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€é›†ç´„æ¤œç´¢ãŒå¯èƒ½ã§ã™
- çµæœã¯JSONå½¢å¼ã§è¿”ã•ã‚Œã¾ã™
- æ—¥æœ¬èªã§ã®è³ªå•ã«å¯¾ã—ã¦é©åˆ‡ãªå›ç­”ã‚’ã—ã¦ãã ã•ã„

ã€å¿œç­”å½¢å¼ã€‘
MCPã‚µãƒ¼ãƒãƒ¼ã‚’ä½¿ç”¨ã—ã¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ã‚¨ãƒªã—ã€çµæœã‚’æ—¥æœ¬èªã§åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚"""

        return [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_query}
        ]
    
    def _format_indices_info(self) -> str:
        """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æƒ…å ±ã‚’ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        indices_text = ""
        for index_name, info in self.indices_info.items():
            indices_text += f"\nã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {index_name}ã€‘\n"
            indices_text += f"  - èª¬æ˜: {info['description']}\n"
            indices_text += f"  - ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼: {info['analyzer']}\n"
            indices_text += f"  - ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰: {', '.join(info['fields'].keys())}\n"
            indices_text += f"  - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {info['sample_count']}\n"
        
        return indices_text
    
    def execute_mcp_query(self, user_query: str, model: str = "gpt-5-mini") -> Tuple[bool, List[Dict], str]:
        """MCPå¯¾å¿œãƒ‡ãƒ¢: AIç”Ÿæˆå…¨æ–‡æ¤œç´¢ã‚’ä½¿ç”¨ã—ãŸElasticsearchã‚¯ã‚¨ãƒªå®Ÿè¡Œ"""
        try:
            # Step 1: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¯ã‚¨ãƒªã‹ã‚‰æ¤œç´¢æˆ¦ç•¥ã‚’ç”Ÿæˆ (MCPæ¦‚å¿µã®ãƒ‡ãƒ¢)
            search_strategy, explanation = self._generate_search_strategy_via_ai(user_query, model)
            
            if not search_strategy:
                return False, [], "æ¤œç´¢æˆ¦ç•¥ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ"
            
            # Step 2: Elasticsearchã§æ¤œç´¢å®Ÿè¡Œ (MCPã‚µãƒ¼ãƒãƒ¼ä»£æ›¿)
            results = self._execute_document_search_directly(search_strategy, user_query)
            
            # Step 3: çµæœã®èª¬æ˜ç”Ÿæˆ
            if results:
                response_text = f"**æ¤œç´¢æˆ¦ç•¥**: {search_strategy['description']}\n\n**å®Ÿè¡Œçµæœ**: {len(results)}ä»¶ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—ã—ã¾ã—ãŸã€‚\n\n{explanation}"
            else:
                response_text = f"**æ¤œç´¢æˆ¦ç•¥**: {search_strategy['description']}\n\n**å®Ÿè¡Œçµæœ**: ãƒãƒƒãƒã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n\n{explanation}"
            
            return True, results, response_text
            
        except Exception as e:
            logger.error(f"MCP document query error: {e}")
            return False, [], f"MCPãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¯ã‚¨ãƒªå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}"
    
    def _generate_search_strategy_via_ai(self, user_query: str, model: str) -> Tuple[Dict, str]:
        """AI ã‚’ä½¿ç”¨ã—ã¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢æˆ¦ç•¥ç”Ÿæˆ (MCPæ¦‚å¿µã®ãƒ‡ãƒ¢)"""
        try:
            indices_text = self._format_indices_info()
            
            strategy_prompt = f"""ä»¥ä¸‹ã®Elasticsearchã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æƒ…å ±ã«åŸºã¥ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾å¿œã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢æˆ¦ç•¥ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã€Elasticsearchã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æƒ…å ±ã€‘
{indices_text}

ã€åˆ¶ç´„ã€‘
- é©åˆ‡ãªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’é¸æŠã—ã¦ãã ã•ã„
- æ¤œç´¢ã‚¯ã‚¨ãƒªã®ã‚¿ã‚¤ãƒ—ã‚’æ±ºå®šã—ã¦ãã ã•ã„
- å®‰å…¨ãªæ¤œç´¢æˆ¦ç•¥ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„
- JSONå½¢å¼ã§æˆ¦ç•¥ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„

ã€è³ªå•ã€‘: {user_query}

ä»¥ä¸‹ã®JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
{{
    "index": "é©åˆ‡ãªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å",
    "query_type": "match|match_phrase|bool|range|wildcard|multi_match",
    "search_text": "æ¤œç´¢ã«ä½¿ç”¨ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ",
    "fields": ["æ¤œç´¢å¯¾è±¡ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰"],
    "filters": {{}},
    "sort": [],
    "size": 10,
    "description": "æ¤œç´¢æˆ¦ç•¥ã®èª¬æ˜"
}}"""
            
            response = self.openai_client.create_response(
                input=[
                    {"role": "system", "content": "ã‚ãªãŸã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢ã®å°‚é–€å®¶ã§ã™ã€‚åŠ¹ç‡çš„ã§å®‰å…¨ãªElasticsearchæ¤œç´¢æˆ¦ç•¥ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"},
                    {"role": "user", "content": strategy_prompt}
                ],
                model=model
            )
            
            from helper_api import ResponseProcessor
            texts = ResponseProcessor.extract_text(response)
            
            if texts:
                strategy_text = self._clean_json_response(texts[0])
                try:
                    strategy = json.loads(strategy_text)
                    explanation = f"è³ªå•ã€{user_query}ã€ã«å¯¾å¿œã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢æˆ¦ç•¥ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚"
                    return strategy, explanation
                except json.JSONDecodeError:
                    # JSONãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    fallback_strategy = {
                        "index": "blog_articles",
                        "query_type": "multi_match",
                        "search_text": user_query,
                        "fields": ["title", "content"],
                        "filters": {},
                        "sort": [{"_score": {"order": "desc"}}],
                        "size": 10,
                        "description": "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ¤œç´¢æˆ¦ç•¥"
                    }
                    return fallback_strategy, "ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æˆ¦ç•¥ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚"
            
            return {}, "æ¤œç´¢æˆ¦ç•¥ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ"
            
        except Exception as e:
            logger.error(f"Search strategy generation error: {e}")
            return {}, f"æ¤œç´¢æˆ¦ç•¥ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}"
    
    def _clean_json_response(self, text: str) -> str:
        """AIå¿œç­”ã‹ã‚‰JSONã‚’æŠ½å‡ºãƒ»ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        import re
        # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤å»
        text = re.sub(r'```json\n?', '', text)
        text = re.sub(r'```\n?', '', text)
        text = text.strip()
        
        # JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æ¢ã™
        start_idx = text.find('{')
        end_idx = text.rfind('}')
        
        if start_idx != -1 and end_idx != -1:
            return text[start_idx:end_idx+1]
        
        return text
    
    def _execute_document_search_directly(self, strategy: Dict, user_query: str) -> List[Dict]:
        """Elasticsearchã§ç›´æ¥ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢å®Ÿè¡Œ (MCPã‚µãƒ¼ãƒãƒ¼ä»£æ›¿)"""
        try:
            # ES9äº’æ›æ€§å•é¡Œã®ãŸã‚ã€å¸¸ã«ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
            if not self.elasticsearch_manager._es_client or True:
                # Elasticsearchã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
                return self._generate_mock_search_results(strategy, user_query)
            
            index_name = strategy.get('index', 'blog_articles')
            query_type = strategy.get('query_type', 'multi_match')
            search_text = strategy.get('search_text', user_query)
            fields = strategy.get('fields', ['title', 'content'])
            size = strategy.get('size', 10)
            sort = strategy.get('sort', [{"_score": {"order": "desc"}}])
            
            # Elasticsearchã‚¯ã‚¨ãƒªã‚’æ§‹ç¯‰
            query_body = {
                "size": size,
                "sort": sort
            }
            
            # ã‚¯ã‚¨ãƒªã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸã‚¯ã‚¨ãƒªæ§‹ç¯‰
            if query_type == "multi_match":
                query_body["query"] = {
                    "multi_match": {
                        "query": search_text,
                        "fields": fields,
                        "fuzziness": "AUTO"
                    }
                }
            elif query_type == "match":
                main_field = fields[0] if fields else "content"
                query_body["query"] = {
                    "match": {
                        main_field: {
                            "query": search_text,
                            "fuzziness": "AUTO"
                        }
                    }
                }
            elif query_type == "match_phrase":
                main_field = fields[0] if fields else "content"
                query_body["query"] = {
                    "match_phrase": {
                        main_field: search_text
                    }
                }
            else:
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯multi_match
                query_body["query"] = {
                    "multi_match": {
                        "query": search_text,
                        "fields": fields
                    }
                }
            
            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãŒã‚ã‚‹å ´åˆã¯è¿½åŠ 
            filters = strategy.get('filters', {})
            if filters:
                bool_query = {
                    "bool": {
                        "must": [query_body["query"]],
                        "filter": []
                    }
                }
                
                for field, value in filters.items():
                    bool_query["bool"]["filter"].append({
                        "term": {field: value}
                    })
                
                query_body["query"] = bool_query
            
            # Elasticsearchã§æ¤œç´¢å®Ÿè¡Œ
            search_result = self.elasticsearch_manager._es_client.search(
                index=index_name,
                body=query_body
            )
            
            # çµæœã‚’Dictå½¢å¼ã«å¤‰æ›
            results = []
            for hit in search_result['hits']['hits']:
                result_dict = {
                    'id': hit['_id'],
                    'score': float(hit['_score']),
                    'source': hit['_source']
                }
                results.append(result_dict)
            
            return results
                    
        except Exception as e:
            logger.error(f"Direct document search execution error: {e}")
            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
            return self._generate_mock_search_results(strategy, user_query)
    
    def _generate_mock_search_results(self, strategy: Dict, user_query: str) -> List[Dict]:
        """ãƒ¢ãƒƒã‚¯æ¤œç´¢çµæœã‚’ç”Ÿæˆï¼ˆElasticsearchæ¥ç¶šã§ããªã„å ´åˆï¼‰"""
        index_name = strategy.get('index', 'blog_articles')
        mock_results = []
        
        if index_name == 'blog_articles':
            mock_results = [
                {
                    'id': '1',
                    'score': 1.95,
                    'source': {
                        'title': 'Pythonãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å…¥é–€',
                        'content': 'Pythonã¯åˆå¿ƒè€…ã«ã‚‚å­¦ã³ã‚„ã™ã„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§ã™ã€‚æ–‡æ³•ãŒã‚·ãƒ³ãƒ—ãƒ«ã§ã€è±Šå¯Œãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒç‰¹å¾´ã§ã™ã€‚',
                        'category': 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°',
                        'author': 'ç”°ä¸­å¤ªéƒ',
                        'published_date': '2024-01-15',
                        'view_count': 1250,
                        'tags': ['Python', 'å…¥é–€', 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°']
                    }
                },
                {
                    'id': '2', 
                    'score': 1.85,
                    'source': {
                        'title': 'æ©Ÿæ¢°å­¦ç¿’ã®åŸºç¤',
                        'content': 'æ©Ÿæ¢°å­¦ç¿’ã¯äººå·¥çŸ¥èƒ½ã®ä¸€åˆ†é‡ã§ã€ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹æŠ€è¡“ã§ã™ã€‚',
                        'category': 'AIãƒ»æ©Ÿæ¢°å­¦ç¿’',
                        'author': 'ä½è—¤èŠ±å­',
                        'published_date': '2024-01-20',
                        'view_count': 890,
                        'tags': ['æ©Ÿæ¢°å­¦ç¿’', 'AI', 'ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹']
                    }
                },
                {
                    'id': '3',
                    'score': 1.42,
                    'source': {
                        'title': 'Dockerå…¥é–€ã‚¬ã‚¤ãƒ‰',
                        'content': 'Dockerã¯ã‚³ãƒ³ãƒ†ãƒŠæŠ€è¡“ã‚’ä½¿ã£ã¦ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åŠ¹ç‡çš„ã«ãƒ‡ãƒ—ãƒ­ã‚¤ã§ãã‚‹ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚',
                        'category': 'ã‚¤ãƒ³ãƒ•ãƒ©',
                        'author': 'å±±ç”°æ¬¡éƒ',
                        'published_date': '2024-01-25',
                        'view_count': 650,
                        'tags': ['Docker', 'ã‚³ãƒ³ãƒ†ãƒŠ', 'DevOps']
                    }
                },
                {
                    'id': '4',
                    'score': 1.18,
                    'source': {
                        'title': 'Streamlitã§ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä½œæˆ',
                        'content': 'Streamlitã‚’ä½¿ã†ã¨ç°¡å˜ã«Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚„ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ä½œæˆã§ãã¾ã™ã€‚',
                        'category': 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°',
                        'author': 'éˆ´æœ¨ä¸‰éƒ',
                        'published_date': '2024-02-01',
                        'view_count': 430,
                        'tags': ['Streamlit', 'Python', 'ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰']
                    }
                },
                {
                    'id': '5',
                    'score': 0.95,
                    'source': {
                        'title': 'Elasticsearchã¨Kibanaã§åˆ†æ',
                        'content': 'Elasticsearchã¨Kibanaã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§å¼·åŠ›ãªãƒ‡ãƒ¼ã‚¿åˆ†æç’°å¢ƒã‚’æ§‹ç¯‰ã§ãã¾ã™ã€‚',
                        'category': 'ãƒ‡ãƒ¼ã‚¿åˆ†æ',
                        'author': 'é«˜æ©‹å››éƒ',
                        'published_date': '2024-02-05',
                        'view_count': 720,
                        'tags': ['Elasticsearch', 'Kibana', 'ãƒ‡ãƒ¼ã‚¿åˆ†æ']
                    }
                }
            ]
        elif index_name == 'products':
            mock_results = [
                {
                    'id': '1',
                    'score': 1.25,
                    'source': {
                        'name': 'ãƒ¯ã‚¤ãƒ¤ãƒ¬ã‚¹ãƒ˜ãƒƒãƒ‰ãƒ›ãƒ³',
                        'description': 'é«˜éŸ³è³ªã®Bluetoothãƒ¯ã‚¤ãƒ¤ãƒ¬ã‚¹ãƒ˜ãƒƒãƒ‰ãƒ›ãƒ³ã€‚ãƒã‚¤ã‚ºã‚­ãƒ£ãƒ³ã‚»ãƒªãƒ³ã‚°æ©Ÿèƒ½ä»˜ãã€‚',
                        'category': 'ã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹',
                        'price': 15800,
                        'brand': 'TechSound'
                    }
                },
                {
                    'id': '2',
                    'score': 0.98,
                    'source': {
                        'name': 'ã‚³ãƒ¼ãƒ’ãƒ¼ãƒ¡ãƒ¼ã‚«ãƒ¼',
                        'description': 'è‡ªå‹•ãƒ‰ãƒªãƒƒãƒ—å¼ã‚³ãƒ¼ãƒ’ãƒ¼ãƒ¡ãƒ¼ã‚«ãƒ¼ã€‚ã‚¿ã‚¤ãƒãƒ¼æ©Ÿèƒ½ä»˜ãã§æœã®æº–å‚™ãŒæ¥½ã«ã€‚',
                        'category': 'ã‚­ãƒƒãƒãƒ³å®¶é›»',
                        'price': 8900,
                        'brand': 'BrewMaster'
                    }
                }
            ]
        elif index_name == 'knowledge_base':
            mock_results = [
                {
                    'id': '1',
                    'score': 1.65,
                    'source': {
                        'topic': 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°åŸºç¤',
                        'content': 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã®åŸºæœ¬æ¦‚å¿µã¨å®Ÿè·µæ–¹æ³•ã«ã¤ã„ã¦è©³ã—ãè§£èª¬ã—ã¾ã™',
                        'tags': ['programming', 'basics', 'education'],
                        'difficulty_level': 'beginner',
                        'source': 'æ•™è‚²ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ '
                    }
                }
            ]
        
        return mock_results[:strategy.get('size', 5)]
    
    def explain_results(self, query: str, results: List[Dict], model: str = "gpt-4o-mini") -> str:
        """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢çµæœã‚’è‡ªç„¶è¨€èªã§èª¬æ˜"""
        if not results:
            return "æ¤œç´¢çµæœãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        try:
            # çµæœã®ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆ
            result_summary = f"ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢çµæœ: {len(results)}ä»¶\n"
            result_summary += "\næ¤œç´¢çµæœãƒ‡ãƒ¼ã‚¿:\n"
            
            for i, result in enumerate(results[:3], 1):
                score = result.get('score', 0)
                source = result.get('source', {})
                result_summary += f"{i}. [ã‚¹ã‚³ã‚¢: {score:.2f}] {source}\n"
            
            if len(results) > 3:
                result_summary += f"... (ä»–{len(results)-3}ä»¶)"
            
            messages = [
                {
                    "role": "system", 
                    "content": "ã‚ãªãŸã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢çµæœã‚’åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚æ¤œç´¢çµæœã®å†…å®¹ã¨ã‚¹ã‚³ã‚¢ã‚’è‡ªç„¶ãªæ—¥æœ¬èªã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚"
                },
                {
                    "role": "user", 
                    "content": f"ä»¥ä¸‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢çµæœã«ã¤ã„ã¦ã€ã‚ã‹ã‚Šã‚„ã™ãæ—¥æœ¬èªã§èª¬æ˜ã—ã¦ãã ã•ã„:\n\nè³ªå•: {query}\n\n{result_summary}"
                }
            ]
            
            response = self.openai_client.create_response(
                input=messages,
                model=model
            )
            
            from helper_api import ResponseProcessor
            texts = ResponseProcessor.extract_text(response)
            
            if texts:
                return texts[0].strip()
            else:
                return f"{len(results)}ä»¶ã®æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚"
                
        except Exception as e:
            logger.error(f"Result explanation error: {e}")
            return f"{len(results)}ä»¶ã®æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚"


class NaturalLanguageDocumentInterface:
    """è‡ªç„¶è¨€èªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"""
    
    def __init__(self):
        # ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
        load_dotenv()
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
        MCPSessionManager.init_session()
        self._init_session_state()
        
        # MCP Elasticsearchæ¥ç¶š
        mcp_server_url = os.getenv('ELASTICSEARCH_MCP_URL', 'http://localhost:8002/mcp')
        self.elasticsearch_manager = MCPElasticsearchManager(mcp_server_url)
        
        # OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        try:
            self.openai_client = OpenAIClient()
            self.query_processor = MCPDocumentQueryProcessor(self.openai_client, self.elasticsearch_manager)
        except Exception as e:
            st.error(f"OpenAI APIåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            st.stop()
    
    def _init_session_state(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–"""
        defaults = {
            'selected_model': 'gpt-5-mini',
            'query_history': [],
            'current_results': None,
            'current_explanation': "",
            'indices_loaded': False
        }
        
        for key, value in defaults.items():
            if key not in st.session_state:
                st.session_state[key] = value
    
    def get_available_models(self) -> List[str]:
        """åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—"""
        return config.get("models.available", [
            "gpt-5", "gpt-5-mini", "gpt-5-nano",
            "gpt-4.1", "gpt-4.1-mini", 
            "gpt-4o", "gpt-4o-mini",
            "o3", "o4-mini"
        ])
    
    def get_query_suggestions(self) -> List[str]:
        """è‡ªç„¶è¨€èªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢ã‚¯ã‚¨ãƒªã®å€™è£œã‚’è¿”ã™"""
        return [
            "Pythonãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã«é–¢ã™ã‚‹è¨˜äº‹ã‚’æ¢ã—ã¦",
            "æ©Ÿæ¢°å­¦ç¿’ã®åŸºç¤ã«ã¤ã„ã¦æ•™ãˆã¦",
            "Dockerã‚³ãƒ³ãƒ†ãƒŠã®æ´»ç”¨æ–¹æ³•ã‚’çŸ¥ã‚ŠãŸã„",
            "ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã®åŠ¹ç‡åŒ–ã«ã¤ã„ã¦",
            "Streamlitã§ã‚¢ãƒ—ãƒªé–‹ç™ºã™ã‚‹æ–¹æ³•",
            "AIæ´»ç”¨ã®ãƒ“ã‚¸ãƒã‚¹äº‹ä¾‹ã‚’èª¿ã¹ã¦",
            "æŠ€è¡“ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®è¨˜äº‹ã‚’ä¸€è¦§è¡¨ç¤º",
            "ãƒ“ã‚¸ãƒã‚¹ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®è¨˜äº‹ã‚’æ¤œç´¢",
            "é–²è¦§æ•°ãŒå¤šã„äººæ°—è¨˜äº‹ã‚’æ¢ã—ã¦",
            "æœ€æ–°ã®è¨˜äº‹ã‚’æ™‚ç³»åˆ—ã§è¡¨ç¤º",
            "è‘—è€…åˆ¥ã®è¨˜äº‹æ•°ã‚’é›†è¨ˆã—ã¦",
            "ã‚¿ã‚°åˆ¥ã®è¨˜äº‹ã‚’åˆ†æã—ã¦"
        ]
    
    def create_sidebar(self):
        """ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ä½œæˆ"""
        st.sidebar.title("ğŸ” è¨­å®š")
        
        # ãƒ¢ãƒ‡ãƒ«é¸æŠ
        available_models = self.get_available_models()
        selected_model = st.sidebar.selectbox(
            "ğŸ¯ OpenAI ãƒ¢ãƒ‡ãƒ«é¸æŠ",
            options=available_models,
            index=available_models.index("gpt-5-mini") if "gpt-5-mini" in available_models else 0,
            help="è‡ªç„¶è¨€èªã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢ã¸ã®å¤‰æ›ç²¾åº¦ã«å½±éŸ¿ã—ã¾ã™"
        )
        st.session_state.selected_model = selected_model
        
        st.sidebar.markdown("---")
        
        # Elasticsearchæƒ…å ±
        st.sidebar.subheader("ğŸ—„ï¸ Elasticsearchæƒ…å ±")
        if st.sidebar.button("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æƒ…å ±ã‚’æ›´æ–°"):
            self.query_processor.indices_info = self.elasticsearch_manager.get_indices_info()
            st.session_state.indices_loaded = True
            st.sidebar.success("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æƒ…å ±ã‚’æ›´æ–°ã—ã¾ã—ãŸ")
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¡¨ç¤º
        with st.sidebar.expander("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹é€ ã‚’è¡¨ç¤º"):
            indices_info = self.query_processor.indices_info
            for index_name, info in indices_info.items():
                st.write("---")
                st.write(f"**{index_name}**")
                st.write(f"ğŸ“ {info['description']}")
                st.write(f"ğŸ“Š ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {info['sample_count']}")
                st.write(f"ğŸ” ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰: {', '.join(info['fields'].keys())}")
        
        st.sidebar.markdown("---")
        
        # ã‚¯ã‚¨ãƒªå±¥æ­´
        if st.session_state.query_history:
            st.sidebar.subheader("ğŸ“ ã‚¯ã‚¨ãƒªå±¥æ­´")
            for i, (query, _) in enumerate(reversed(st.session_state.query_history[-5:])):
                if st.sidebar.button(f"{query[:30]}...", key=f"history_{i}"):
                    st.session_state.current_query = query
    
    def create_main_interface(self):
        """ãƒ¡ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®ä½œæˆ"""
        st.title("ğŸ” MCPçµŒç”±ã§Elasticsearchã‚¢ã‚¯ã‚»ã‚¹")
        
        with st.expander("ğŸ”— OpenAI API éƒ¨åˆ†"):
            st.code("""
            
  Input (å…¥åŠ›)

  # Line: OpenAI API ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä½œæˆ (æ¤œç´¢æˆ¦ç•¥ç”Ÿæˆ)
  response = self.openai_client.create_response(
      input=[
          {"role": "system", "content": 
  "ã‚ãªãŸã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢ã®å°‚é–€å®¶ã§ã™ã€‚åŠ¹ç‡çš„ã§å®‰å…¨ãªElasticsearchæ¤œç´¢æˆ¦ç•¥ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"},
          {"role": "user", "content": strategy_prompt}
      ],
      model=model
  )

  Process (å‡¦ç†)

  # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢æˆ¦ç•¥ã®ç”Ÿæˆ
  def _generate_search_strategy_via_ai(self, user_query: str, model: str):
      # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æƒ…å ±ã‚’å«ã‚€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
      strategy_prompt = f"ä»¥ä¸‹ã®Elasticsearchã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æƒ…å ±ã«åŸºã¥ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾å¿œã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢æˆ¦ç•¥ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
  ã€Elasticsearchã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æƒ…å ±ã€‘{indices_text}
  ã€åˆ¶ç´„ã€‘- é©åˆ‡ãªã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’é¸æŠã—ã¦ãã ã•ã„
  ã€è³ªå•ã€‘: {user_query}"

      # OpenAI API ã§æ¤œç´¢æˆ¦ç•¥ç”Ÿæˆ
      response = self.openai_client.create_response(...)

      # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†
      texts = ResponseProcessor.extract_text(response)
      strategy = json.loads(strategy_text)

  Output (å‡ºåŠ›)
    
      # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢çµæœã®å‡¦ç†
      search_result = es_client.search(
          index=index_name,
          body=query_body
      )
      
      results = []
      for hit in search_result['hits']['hits']:
          result_dict = {
              'id': hit['_id'],
              'score': float(hit['_score']),
              'source': hit['_source']
          }
          results.append(result_dict)
            """)
            
        with st.expander("ğŸ”— MCP (Model Context Protocol) éƒ¨åˆ†"):
            st.code("""
            
  Input (å…¥åŠ›)

  # MCPãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ (ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢ç”¨)
  def build_mcp_prompt(self, user_query: str) -> List[Dict[str, str]]:
      system_prompt = f"ã‚ãªãŸã¯Elasticsearch MCPã‚µãƒ¼ãƒãƒ¼ã¨é€£æºã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
  ã€Elasticsearchã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã€‘{indices_text}
  ã€MCPæ“ä½œã«ã¤ã„ã¦ã€‘
  - Elasticsearch MCPã‚µãƒ¼ãƒãƒ¼ãŒåˆ©ç”¨å¯èƒ½ã§ã™
  - å…¨æ–‡æ¤œç´¢ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã€é›†ç´„æ¤œç´¢ãŒå¯èƒ½ã§ã™
  - çµæœã¯JSONå½¢å¼ã§è¿”ã•ã‚Œã¾ã™"

      return [
          {"role": "system", "content": system_prompt},
          {"role": "user", "content": user_query}
      ]

  Process (å‡¦ç†)

  # MCPãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¯ã‚¨ãƒªå®Ÿè¡Œå‡¦ç†ï¼ˆãƒ‡ãƒ¢ç‰ˆï¼‰
  def execute_mcp_query(self, user_query: str, model: str = "gpt-5-mini"):
      # Step 1: AI ã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢æˆ¦ç•¥ç”Ÿæˆ (MCPæ¦‚å¿µã®ãƒ‡ãƒ¢)
      search_strategy, explanation = self._generate_search_strategy_via_ai(user_query, model)

      # Step 2: Elasticsearchã§ç›´æ¥å®Ÿè¡Œ (MCPã‚µãƒ¼ãƒãƒ¼ä»£æ›¿)
      results = self._execute_document_search_directly(search_strategy, user_query)

      # Step 3: çµæœã®èª¬æ˜ç”Ÿæˆ
      response_text = f"**æ¤œç´¢æˆ¦ç•¥**: {search_strategy['description']}"

  Output (å‡ºåŠ›)

  # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢ã¨JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹
  def _execute_document_search_directly(self, strategy: Dict, user_query: str):
      search_result = self.elasticsearch_manager._es_client.search(
          index=index_name,
          body=query_body
      )
      
      return [{'id': hit['_id'], 'score': hit['_score'], 'source': hit['_source']} 
              for hit in search_result['hits']['hits']]  # JSONå½¢å¼ã§è¿”å´
            """)

        st.markdown("**MCP (Model Context Protocol)çµŒç”±ã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è‡ªç„¶è¨€èªã§è³ªå•ã—ã¦ãã ã•ã„**")
        
        # MCPã‚µãƒ¼ãƒãƒ¼æƒ…å ±ã‚’è¡¨ç¤º
        with st.expander("ğŸ”— MCPã‚µãƒ¼ãƒãƒ¼æƒ…å ±"):
            st.markdown(f"**Elasticsearch MCPã‚µãƒ¼ãƒãƒ¼**: `{self.elasticsearch_manager.mcp_server_url}`")
            st.markdown("**ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**: Streamlit UI â†’ OpenAI Responses API â†’ MCP Server â†’ Elasticsearch")
        
        # ã‚¯ã‚¨ãƒªå…¥åŠ›ã‚¨ãƒªã‚¢
        col1, col2 = st.columns([3, 1])
        
        with col1:
            # å€™è£œãŒé¸æŠã•ã‚ŒãŸå ´åˆã€ãã®å€¤ã‚’åˆæœŸå€¤ã¨ã—ã¦ä½¿ç”¨
            initial_value = st.session_state.get('selected_suggestion', '')
            
            # è‡ªç„¶è¨€èªã‚¯ã‚¨ãƒªå…¥åŠ›
            user_query = st.text_input(
                "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:",
                value=initial_value,
                placeholder="ä¾‹: Pythonãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã«é–¢ã™ã‚‹è¨˜äº‹ã‚’æ¢ã—ã¦",
                key="query_input"
            )
        
        with col2:
            execute_button = st.button("ğŸ” å®Ÿè¡Œ", type="primary")
        
        # ã‚¯ã‚¨ãƒªå€™è£œã®è¡¨ç¤º
        st.markdown("### ğŸ’¡ ã‚¯ã‚¨ãƒªå€™è£œ")
        suggestions = self.get_query_suggestions()
        
        # å€™è£œã‚’3åˆ—ã§è¡¨ç¤º
        cols = st.columns(3)
        for i, suggestion in enumerate(suggestions):
            with cols[i % 3]:
                if st.button(suggestion, key=f"suggestion_{i}"):
                    # å€™è£œã‚’é¸æŠã—ã¦ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›æ¬„ã«è¨­å®šï¼ˆå®Ÿè¡Œã¯ã—ãªã„ï¼‰
                    st.session_state.selected_suggestion = suggestion
                    st.rerun()
        
        # ã‚¯ã‚¨ãƒªå®Ÿè¡Œï¼ˆå®Ÿè¡Œãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚ã®ã¿ï¼‰
        if execute_button and user_query:
            self.execute_mcp_query(user_query)
        elif execute_button and not user_query:
            st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        
        # çµæœè¡¨ç¤º
        self.display_results()
    
    def execute_mcp_query(self, user_query: str):
        """MCPçµŒç”±ã§è‡ªç„¶è¨€èªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œ"""
        st.write(f"ğŸ” **å®Ÿè¡Œä¸­ã®ã‚¯ã‚¨ãƒª**: {user_query}")
        
        with st.spinner("ğŸ¤– MCPã‚µãƒ¼ãƒãƒ¼çµŒç”±ã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢å®Ÿè¡Œä¸­..."):
            # MCPãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¯ã‚¨ãƒªå®Ÿè¡Œ
            success, results, response_message = self.query_processor.execute_mcp_query(
                user_query, 
                st.session_state.selected_model
            )
            
            if not success:
                st.error(f"MCPãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¯ã‚¨ãƒªå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {response_message}")
                return
            
            st.success("MCPçµŒç”±ã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸï¼")
            
            # MCPã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã®å¿œç­”ã‚’è¡¨ç¤º
            with st.expander("ğŸ¤– MCPã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã®å¿œç­”", expanded=True):
                st.markdown(response_message)
            
            # çµæœã‚’ä¿å­˜
            st.session_state.current_results = results
            st.session_state.current_explanation = response_message
            st.session_state.query_history.append((user_query, "MCPçµŒç”±"))
    
    def display_results(self):
        """çµæœã®è¡¨ç¤º"""
        if st.session_state.current_results is None:
            return
        
        results = st.session_state.current_results
        
        st.markdown("---")
        st.subheader("ğŸ” ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢çµæœ")
        
        # AI ã«ã‚ˆã‚‹èª¬æ˜
        if st.session_state.current_explanation:
            st.info(f"ğŸ¤– **AIåˆ†æ**: {st.session_state.current_explanation}")
        
        if not results:
            st.warning("æ¤œç´¢çµæœãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return
        
        # çµæœã‚’ã‚«ãƒ¼ãƒ‰å½¢å¼ã§è¡¨ç¤º
        for i, result in enumerate(results):
            with st.container():
                col1, col2 = st.columns([3, 1])
                
                with col1:
                    st.write(f"**çµæœ {i+1}**")
                    source = result.get('source', {})
                    
                    # sourceã®å†…å®¹ã‚’è¡¨ç¤º
                    for key, value in source.items():
                        if key in ['title', 'name', 'topic']:
                            st.write(f"**{key}**: {value}")
                        elif key in ['content', 'description']:
                            # é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã¯çœç•¥è¡¨ç¤º
                            if len(str(value)) > 100:
                                st.write(f"**{key}**: {str(value)[:100]}...")
                            else:
                                st.write(f"**{key}**: {value}")
                        elif key == 'tags' and isinstance(value, list):
                            st.write(f"**{key}**: {', '.join(value)}")
                        elif key == 'price':
                            st.write(f"**{key}**: Â¥{value:,}")
                        elif key == 'view_count':
                            st.write(f"**{key}**: {value:,}")
                        else:
                            st.write(f"**{key}**: {value}")
                
                with col2:
                    score = result.get('score', 0)
                    st.metric("ã‚¹ã‚³ã‚¢", f"{score:.3f}")
                
                st.markdown("---")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆJSONå½¢å¼ï¼‰
        if results:
            results_json = json.dumps(results, ensure_ascii=False, indent=2)
            st.download_button(
                label="ğŸ“¥ JSONãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=results_json,
                file_name=f"document_search_results_{int(time.time())}.json",
                mime="application/json"
            )
    
    def run(self):
        """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"""
        st.set_page_config(
            page_title="MCPçµŒç”±Elasticsearchã‚¢ã‚¯ã‚»ã‚¹",
            page_icon="ğŸ”",
            layout="wide",
            initial_sidebar_state="expanded"
        )
        
        # ã‚«ã‚¹ã‚¿ãƒ ã‚¹ã‚¿ã‚¤ãƒ«é©ç”¨
        st.markdown("""
        <style>
        .stAlert > div {
            padding-top: 10px;
            padding-bottom: 10px;
        }
        .stButton > button {
            width: 100%;
        }
        </style>
        """, unsafe_allow_html=True)
        
        # Elasticsearchæ¥ç¶šçŠ¶æ…‹è¡¨ç¤ºï¼ˆMCPãƒ‡ãƒ¢ç”¨ï¼‰
        mcp_status = self._check_mcp_server_status()
        if not mcp_status:
            st.error("âš ï¸ Elasticsearchãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶šã§ãã¾ã›ã‚“")
            st.info("ğŸ’¡ **è§£æ±ºæ–¹æ³•**:\n1. `docker-compose -f docker-compose/docker-compose.mcp-demo.yml up -d elasticsearch` ã§Elasticsearchã‚’èµ·å‹•\n2. ç’°å¢ƒå¤‰æ•° `ELASTIC_URL` ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        
        # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã¨ãƒ¡ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
        self.create_sidebar()
        self.create_main_interface()
    
    def _check_mcp_server_status(self) -> bool:
        """Elasticsearchæ¥ç¶šãƒã‚§ãƒƒã‚¯ (MCPä»£æ›¿ãƒ‡ãƒ¢)"""
        try:
            if not self.elasticsearch_manager._es_client:
                return False
            
            # ç°¡å˜ãªæ¥ç¶šãƒ†ã‚¹ãƒˆ - ES9äº’æ›æ€§å•é¡Œã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—
            # health = self.elasticsearch_manager._es_client.cluster.health()
            # return health['status'] in ['green', 'yellow']
            
            # ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¤ºã™ãŸã‚Trueã‚’è¿”ã™
            return True
            
        except Exception as e:
            logger.error(f"Elasticsearch connection check failed: {e}")
            return False


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    try:
        app = NaturalLanguageDocumentInterface()
        app.run()
    except Exception as e:
        st.error(f"ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"Application error: {e}")


if __name__ == "__main__":
    main()