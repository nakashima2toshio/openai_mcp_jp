# mcp_postgresql.py - MCPçµŒç”±ã§è‡ªç„¶è¨€èªã§PostgreSQLã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹Streamlitã‚¢ãƒ—ãƒª
# streamlit run mcp_postgresql.py --server.port=8504
# å‰æ: PostgreSQL MCP ã‚µãƒ¼ãƒãƒ¼ãŒãƒãƒ¼ãƒˆ8001ã§èµ·å‹•ã—ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™

import streamlit as st
import os
import pandas as pd
import json
import time
import psycopg2
import psycopg2.extras
from typing import Dict, Any, List, Optional, Tuple
from dotenv import load_dotenv
import plotly.express as px
import plotly.graph_objects as go

# ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from helper_api import OpenAIClient, MessageManager, config, logger
from helper_mcp import MCPSessionManager
from helper_st import UIHelper


class MCPDatabaseManager:
    """MCPå¯¾å¿œPostgreSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œç®¡ç† (ãƒ‡ãƒ¢ç”¨ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ¼ãƒ‰)"""
    
    def __init__(self, mcp_server_url: str = "http://localhost:8001/mcp", pg_conn_str: str = None):
        self.mcp_server_url = mcp_server_url
        self.pg_conn_str = pg_conn_str or "postgresql://testuser:testpass@localhost:5432/testdb"
        self.schema_info = None
        self._cached_schema_info = None
        self._pg_connection = None
    
    def get_schema_info(self) -> Dict[str, Any]:
        """MCPã‚µãƒ¼ãƒãƒ¼çµŒç”±ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ã‚’å–å¾—"""
        if self._cached_schema_info is not None:
            return self._cached_schema_info
            
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ï¼ˆPostgreSQLåˆæœŸåŒ–ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ï¼‰
        default_schema = {
            "customers": [
                {"column_name": "id", "data_type": "integer", "is_nullable": "NO"},
                {"column_name": "name", "data_type": "character varying", "is_nullable": "NO"},
                {"column_name": "email", "data_type": "character varying", "is_nullable": "NO"},
                {"column_name": "age", "data_type": "integer", "is_nullable": "YES"},
                {"column_name": "city", "data_type": "character varying", "is_nullable": "YES"},
                {"column_name": "created_at", "data_type": "timestamp without time zone", "is_nullable": "YES"}
            ],
            "orders": [
                {"column_name": "id", "data_type": "integer", "is_nullable": "NO"},
                {"column_name": "customer_id", "data_type": "integer", "is_nullable": "YES"},
                {"column_name": "product_name", "data_type": "character varying", "is_nullable": "NO"},
                {"column_name": "price", "data_type": "numeric", "is_nullable": "NO"},
                {"column_name": "quantity", "data_type": "integer", "is_nullable": "NO"},
                {"column_name": "order_date", "data_type": "timestamp without time zone", "is_nullable": "YES"}
            ],
            "products": [
                {"column_name": "id", "data_type": "integer", "is_nullable": "NO"},
                {"column_name": "name", "data_type": "character varying", "is_nullable": "NO"},
                {"column_name": "category", "data_type": "character varying", "is_nullable": "YES"},
                {"column_name": "price", "data_type": "numeric", "is_nullable": "NO"},
                {"column_name": "stock_quantity", "data_type": "integer", "is_nullable": "YES"},
                {"column_name": "description", "data_type": "text", "is_nullable": "YES"}
            ]
        }
        
        self._cached_schema_info = default_schema
        return default_schema


class MCPQueryProcessor:
    """MCPçµŒç”±ã§è‡ªç„¶è¨€èªã‚¯ã‚¨ãƒªã‚’å‡¦ç†ã™ã‚‹ãƒ—ãƒ­ã‚»ãƒƒã‚µ"""
    
    def __init__(self, openai_client: OpenAIClient, db_manager: MCPDatabaseManager):
        self.openai_client = openai_client
        self.db_manager = db_manager
        self.schema_info = db_manager.get_schema_info()
    
    def build_mcp_prompt(self, user_query: str) -> List[Dict[str, str]]:
        """MCPçµŒç”±ã§ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        schema_text = self._format_schema_info()
        
        system_prompt = f"""ã‚ãªãŸã¯PostgreSQL MCPã‚µãƒ¼ãƒãƒ¼ã¨é€£æºã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è‡ªç„¶è¨€èªã«ã‚ˆã‚‹è³ªå•ã‚’ç†è§£ã—ã€é©åˆ‡ãªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒã€‘
{schema_text}

ã€MCPæ“ä½œã«ã¤ã„ã¦ã€‘
- PostgreSQL MCPã‚µãƒ¼ãƒãƒ¼ãŒåˆ©ç”¨å¯èƒ½ã§ã™
- SELECTæ“ä½œã®ã¿å®‰å…¨ã«å®Ÿè¡Œå¯èƒ½ã§ã™
- çµæœã¯JSONå½¢å¼ã§è¿”ã•ã‚Œã¾ã™
- æ—¥æœ¬èªã§ã®è³ªå•ã«å¯¾ã—ã¦é©åˆ‡ãªå›ç­”ã‚’ã—ã¦ãã ã•ã„

ã€å¿œç­”å½¢å¼ã€‘
MCPã‚µãƒ¼ãƒãƒ¼ã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ã‚¯ã‚¨ãƒªã—ã€çµæœã‚’æ—¥æœ¬èªã§åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚"""

        return [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_query}
        ]
    
    def _format_schema_info(self) -> str:
        """ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ã‚’ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        schema_text = ""
        for table_name, columns in self.schema_info.items():
            schema_text += f"\nã€ãƒ†ãƒ¼ãƒ–ãƒ«: {table_name}ã€‘\n"
            for col in columns:
                nullable = "NULLå¯" if col['is_nullable'] == 'YES' else "NOT NULL"
                schema_text += f"  - {col['column_name']} ({col['data_type']}) {nullable}\n"
        
        return schema_text
    
    def execute_mcp_query(self, user_query: str, model: str = "gpt-5-mini") -> Tuple[bool, List[Dict], str]:
        """MCPå¯¾å¿œãƒ‡ãƒ¢: AIç”ŸæˆSQLã‚’ä½¿ç”¨ã—ãŸãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒªå®Ÿè¡Œ"""
        try:
            # Step 1: AI ã§SQLç”Ÿæˆ (MCPæ¦‚å¿µã®ãƒ‡ãƒ¢)
            sql_query, explanation = self._generate_sql_via_ai(user_query, model)
            
            if not sql_query:
                return False, [], "SQLç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ"
            
            # Step 2: PostgreSQLã§ç›´æ¥å®Ÿè¡Œ (MCPã‚µãƒ¼ãƒãƒ¼ä»£æ›¿)
            results = self._execute_sql_directly(sql_query)
            
            # Step 3: çµæœã®èª¬æ˜ç”Ÿæˆ
            if results:
                response_text = f"**ç”Ÿæˆã•ã‚ŒãŸSQL**: `{sql_query}`\n\n**å®Ÿè¡Œçµæœ**: {len(results)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸã€‚\n\n{explanation}"
            else:
                response_text = f"**ç”Ÿæˆã•ã‚ŒãŸSQL**: `{sql_query}`\n\n**å®Ÿè¡Œçµæœ**: ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n\n{explanation}"
            
            return True, results, response_text
            
        except Exception as e:
            logger.error(f"MCP query error: {e}")
            return False, [], f"MCPã‚¯ã‚¨ãƒªå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}"
    
    def _generate_sql_via_ai(self, user_query: str, model: str) -> Tuple[str, str]:
        """AI ã‚’ä½¿ç”¨ã—ã¦SQLç”Ÿæˆ (MCPæ¦‚å¿µã®ãƒ‡ãƒ¢)"""
        try:
            schema_text = self._format_schema_info()
            
            sql_prompt = f"""ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒã«åŸºã¥ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾å¿œã™ã‚‹PostgreSQLã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒã€‘
{schema_text}

ã€åˆ¶ç´„ã€‘
- SELECTæ–‡ã®ã¿ç”Ÿæˆã—ã¦ãã ã•ã„
- å®‰å…¨ãªã‚¯ã‚¨ãƒªã‚’å¿ƒãŒã‘ã¦ãã ã•ã„
- SQLã‚¯ã‚¨ãƒªã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆèª¬æ˜ä¸è¦ï¼‰

ã€è³ªå•ã€‘: {user_query}

SQL:"""
            
            response = self.openai_client.create_response(
                input=[
                    {"role": "system", "content": "ã‚ãªãŸã¯SQLç”Ÿæˆã®å°‚é–€å®¶ã§ã™ã€‚å®‰å…¨ã§åŠ¹ç‡çš„ãªPostgreSQLã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"},
                    {"role": "user", "content": sql_prompt}
                ],
                model=model
            )
            
            from helper_api import ResponseProcessor
            texts = ResponseProcessor.extract_text(response)
            
            if texts:
                sql_query = self._clean_sql_query(texts[0])
                explanation = f"è³ªå•ã€{user_query}ã€ã«å¯¾å¿œã™ã‚‹SQLã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚"
                return sql_query, explanation
            
            return "", "SQLç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ"
            
        except Exception as e:
            logger.error(f"SQL generation error: {e}")
            return "", f"SQLç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}"
    
    def _clean_sql_query(self, sql: str) -> str:
        """SQLã‚¯ã‚¨ãƒªã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        import re
        # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤å»
        sql = re.sub(r'```sql\n?', '', sql)
        sql = re.sub(r'```\n?', '', sql)
        sql = sql.strip()
        
        # ã‚»ãƒŸã‚³ãƒ­ãƒ³ã§çµ‚ã‚ã£ã¦ã„ãªã„å ´åˆã¯è¿½åŠ 
        if not sql.endswith(';'):
            sql += ';'
        
        return sql
    
    def _execute_sql_directly(self, sql_query: str) -> List[Dict]:
        """PostgreSQLã§ç›´æ¥SQLå®Ÿè¡Œ (MCPã‚µãƒ¼ãƒãƒ¼ä»£æ›¿)"""
        try:
            # å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯
            if not self._is_safe_query(sql_query):
                raise ValueError("å®‰å…¨ã§ãªã„ã‚¯ã‚¨ãƒªã§ã™")
            
            with psycopg2.connect(
                self.db_manager.pg_conn_str,
                cursor_factory=psycopg2.extras.RealDictCursor
            ) as conn:
                with conn.cursor() as cursor:
                    cursor.execute(sql_query)
                    results = cursor.fetchall()
                    return [dict(row) for row in results]
                    
        except Exception as e:
            logger.error(f"Direct SQL execution error: {e}")
            raise
    
    def _is_safe_query(self, sql: str) -> bool:
        """SQLã‚¯ã‚¨ãƒªã®å®‰å…¨æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
        sql_upper = sql.upper().strip()
        
        # SELECTæ–‡ã®ã¿è¨±å¯
        if not sql_upper.startswith(('SELECT', 'WITH')):
            return False
        
        # å±é™ºãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
        dangerous_keywords = [
            'DROP', 'DELETE', 'INSERT', 'UPDATE', 'ALTER', 'CREATE', 
            'TRUNCATE', 'GRANT', 'REVOKE', 'EXEC', 'EXECUTE'
        ]
        
        for keyword in dangerous_keywords:
            if keyword in sql_upper:
                return False
        
        return True
    
    def explain_results(self, query: str, results: List[Dict], model: str = "gpt-4o-mini") -> str:
        """ã‚¯ã‚¨ãƒªçµæœã‚’è‡ªç„¶è¨€èªã§èª¬æ˜"""
        if not results:
            return "æ¤œç´¢çµæœãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        try:
            # çµæœã®ã‚µãƒãƒªãƒ¼ã‚’ä½œæˆ
            result_summary = f"æ¤œç´¢çµæœ: {len(results)}ä»¶\n"
            if len(results) <= 5:
                result_summary += "\nçµæœãƒ‡ãƒ¼ã‚¿:\n"
                for i, row in enumerate(results, 1):
                    result_summary += f"{i}. {dict(row)}\n"
            else:
                result_summary += f"\næœ€åˆã®3ä»¶:\n"
                for i, row in enumerate(results[:3], 1):
                    result_summary += f"{i}. {dict(row)}\n"
                result_summary += f"... (ä»–{len(results)-3}ä»¶)"
            
            messages = [
                {
                    "role": "system", 
                    "content": "ã‚ãªãŸã¯åˆ†æçµæœã‚’åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ¤œç´¢çµæœã‚’è‡ªç„¶ãªæ—¥æœ¬èªã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚"
                },
                {
                    "role": "user", 
                    "content": f"ä»¥ä¸‹ã®æ¤œç´¢çµæœã«ã¤ã„ã¦ã€ã‚ã‹ã‚Šã‚„ã™ãæ—¥æœ¬èªã§èª¬æ˜ã—ã¦ãã ã•ã„:\n\nè³ªå•: {query}\n\n{result_summary}"
                }
            ]
            
            response = self.openai_client.create_response(
                input=messages,
                model=model
            )
            
            from helper_api import ResponseProcessor
            texts = ResponseProcessor.extract_text(response)
            
            if texts:
                return texts[0].strip()
            else:
                return f"{len(results)}ä»¶ã®çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚"
                
        except Exception as e:
            logger.error(f"Result explanation error: {e}")
            return f"{len(results)}ä»¶ã®çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚"


class NaturalLanguageDBInterface:
    """è‡ªç„¶è¨€èªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"""
    
    def __init__(self):
        # ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
        load_dotenv()
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
        MCPSessionManager.init_session()
        self._init_session_state()
        
        # MCP ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
        mcp_server_url = os.getenv('POSTGRESQL_MCP_URL', 'http://localhost:8001/mcp')
        self.db_manager = MCPDatabaseManager(mcp_server_url)
        
        # OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        try:
            self.openai_client = OpenAIClient()
            self.query_processor = MCPQueryProcessor(self.openai_client, self.db_manager)
        except Exception as e:
            st.error(f"OpenAI APIåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            st.stop()
    
    def _init_session_state(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–"""
        defaults = {
            'selected_model': 'gpt-5-mini',
            'query_history': [],
            'current_results': None,
            'current_explanation': "",
            'schema_loaded': False
        }
        
        for key, value in defaults.items():
            if key not in st.session_state:
                st.session_state[key] = value
    
    def get_available_models(self) -> List[str]:
        """åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—"""
        return config.get("models.available", [
            "gpt-5", "gpt-5-mini", "gpt-5-nano",
            "gpt-4.1", "gpt-4.1-mini", 
            "gpt-4o", "gpt-4o-mini",
            "o3", "o4-mini"
        ])
    
    def get_query_suggestions(self) -> List[str]:
        """è‡ªç„¶è¨€èªã‚¯ã‚¨ãƒªã®å€™è£œã‚’è¿”ã™"""
        return [
            "å…¨ã¦ã®é¡§å®¢ã‚’è¡¨ç¤ºã—ã¦",
            "æ±äº¬åœ¨ä½ã®é¡§å®¢ã‚’è¡¨ç¤ºã—ã¦",
            "30æ­³ä»¥ä¸Šã®é¡§å®¢ã‚’è¡¨ç¤ºã—ã¦",
            "å„éƒ½å¸‚ã®é¡§å®¢æ•°ã‚’æ•™ãˆã¦",
            "æœ€ã‚‚å£²ä¸Šã®é«˜ã„å•†å“ãƒˆãƒƒãƒ—5ã‚’è¡¨ç¤ºã—ã¦",
            "æ³¨æ–‡é‡‘é¡ã®å¹³å‡å€¤ã‚’æ•™ãˆã¦",
            "å„é¡§å®¢ã®ç·æ³¨æ–‡é‡‘é¡ã‚’è¡¨ç¤ºã—ã¦",
            "åœ¨åº«ãŒ10å€‹ä»¥ä¸‹ã®å•†å“ã‚’è¡¨ç¤ºã—ã¦",
            "ã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹å•†å“ã®åœ¨åº«çŠ¶æ³ã‚’æ•™ãˆã¦",
            "æœˆåˆ¥ã®å£²ä¸Šæ¨ç§»ã‚’è¡¨ç¤ºã—ã¦",
            "é¡§å®¢ã®å¹´é½¢åˆ¥åˆ†å¸ƒã‚’æ•™ãˆã¦",
            "æ³¨æ–‡ä»¶æ•°ãŒå¤šã„å•†å“ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¡¨ç¤ºã—ã¦"
        ]
    
    def create_sidebar(self):
        """ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ä½œæˆ"""
        st.sidebar.title("ğŸ¤– è¨­å®š")
        
        # ãƒ¢ãƒ‡ãƒ«é¸æŠ
        available_models = self.get_available_models()
        selected_model = st.sidebar.selectbox(
            "ğŸ¯ OpenAI ãƒ¢ãƒ‡ãƒ«é¸æŠ",
            options=available_models,
            index=available_models.index("gpt-5-mini") if "gpt-5-mini" in available_models else 0,
            help="è‡ªç„¶è¨€èªã‹ã‚‰SQLã¸ã®å¤‰æ›ç²¾åº¦ã«å½±éŸ¿ã—ã¾ã™"
        )
        st.session_state.selected_model = selected_model
        
        st.sidebar.markdown("---")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±
        st.sidebar.subheader("ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±")
        if st.sidebar.button("ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ã‚’æ›´æ–°"):
            self.query_processor.schema_info = self.db_manager.get_schema_info()
            st.session_state.schema_loaded = True
            st.sidebar.success("ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ã‚’æ›´æ–°ã—ã¾ã—ãŸ")
        
        # ã‚¹ã‚­ãƒ¼ãƒè¡¨ç¤º
        with st.sidebar.expander("ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã‚’è¡¨ç¤º"):
            schema_info = self.query_processor.schema_info
            for table_name, columns in schema_info.items():
                st.write("---")
                st.write(f"{table_name}")
                for col in columns:
                    st.write(f"  â€¢ {col['column_name']} ({col['data_type']})")
        
        st.sidebar.markdown("---")
        
        # ã‚¯ã‚¨ãƒªå±¥æ­´
        if st.session_state.query_history:
            st.sidebar.subheader("ğŸ“ ã‚¯ã‚¨ãƒªå±¥æ­´")
            for i, (query, _) in enumerate(reversed(st.session_state.query_history[-5:])):
                if st.sidebar.button(f"{query[:30]}...", key=f"history_{i}"):
                    st.session_state.current_query = query
    
    def create_main_interface(self):
        """ãƒ¡ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®ä½œæˆ"""
        st.title("ğŸ—£ï¸ MCPçµŒç”±ã§PostgreSQLã‚¢ã‚¯ã‚»ã‚¹")
        with st.expander("ğŸ”— OpenAI API éƒ¨åˆ†"):
            st.code("""
            
  Input (å…¥åŠ›)

  # Line 156-162: OpenAI API ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä½œæˆ
  response = self.openai_client.create_response(
      input=[
          {"role": "system", "content":
  "ã‚ãªãŸã¯SQLç”Ÿæˆã®å°‚é–€å®¶ã§ã™ã€‚å®‰å…¨ã§åŠ¹ç‡çš„ãªPostgreSQLã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"},
          {"role": "user", "content": sql_prompt}
      ],
      model=model
  )

  # Line 261-264: çµæœèª¬æ˜ç”¨ OpenAI API å‘¼ã³å‡ºã—
  response = self.openai_client.create_response(
      input=messages,
      model=model
  )

  Process (å‡¦ç†)

  # Line 137-176: AI ã«ã‚ˆã‚‹SQLç”Ÿæˆå‡¦ç†
  def _generate_sql_via_ai(self, user_query: str, model: str) -> Tuple[str, str]:
      # ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ã‚’å«ã‚€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
      sql_prompt = f"ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒã«åŸºã¥ã„ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾å¿œã™ã‚‹PostgreSQLã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
  ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒã€‘{schema_text}
  ã€åˆ¶ç´„ã€‘- SELECTæ–‡ã®ã¿ç”Ÿæˆã—ã¦ãã ã•ã„
  ã€è³ªå•ã€‘: {user_query}"

      # OpenAI API ã§SQLç”Ÿæˆ
      response = self.openai_client.create_response(...)

      # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†
      texts = ResponseProcessor.extract_text(response)
      sql_query = self._clean_sql_query(texts[0])

  Output (å‡ºåŠ›)
    
      # Line 164-172: OpenAI ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºãƒ»ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
      from helper_api import ResponseProcessor
      texts = ResponseProcessor.extract_text(response)
      if texts:
          sql_query = self._clean_sql_query(texts[0])
          explanation = f"è³ªå•ã€{user_query}ã€ã«å¯¾å¿œã™ã‚‹SQLã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚"
          return sql_query, explanation
            """)
        with st.expander("ğŸ”— MCP (Model Context Protocol) éƒ¨åˆ†"):
            st.code("""
            
  Input (å…¥åŠ›)

  # Line 78-100: MCPãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
  def build_mcp_prompt(self, user_query: str) -> List[Dict[str, str]]:
      system_prompt = f"ã‚ãªãŸã¯PostgreSQL MCPã‚µãƒ¼ãƒãƒ¼ã¨é€£æºã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
  ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒã€‘{schema_text}
  ã€MCPæ“ä½œã«ã¤ã„ã¦ã€‘
  - PostgreSQL MCPã‚µãƒ¼ãƒãƒ¼ãŒåˆ©ç”¨å¯èƒ½ã§ã™
  - SELECTæ“ä½œã®ã¿å®‰å…¨ã«å®Ÿè¡Œå¯èƒ½ã§ã™
  - çµæœã¯JSONå½¢å¼ã§è¿”ã•ã‚Œã¾ã™"

      return [
          {"role": "system", "content": system_prompt},
          {"role": "user", "content": user_query}
      ]

  Process (å‡¦ç†)

  # Line 113-135: MCPã‚¯ã‚¨ãƒªå®Ÿè¡Œå‡¦ç†ï¼ˆãƒ‡ãƒ¢ç‰ˆï¼‰
  def execute_mcp_query(self, user_query: str, model: str = "gpt-5-mini") -> Tuple[bool, List[Dict], str]:
      # Step 1: AI ã§SQLç”Ÿæˆ (MCPæ¦‚å¿µã®ãƒ‡ãƒ¢)
      sql_query, explanation = self._generate_sql_via_ai(user_query, model)

      # Step 2: PostgreSQLã§ç›´æ¥å®Ÿè¡Œ (MCPã‚µãƒ¼ãƒãƒ¼ä»£æ›¿)
      results = self._execute_sql_directly(sql_query)

      # Step 3: çµæœã®èª¬æ˜ç”Ÿæˆ
      response_text = f"**ç”Ÿæˆã•ã‚ŒãŸSQL**: `{sql_query}`\n\n**å®Ÿè¡Œçµæœ**: {len(results)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸã€‚"

  Output (å‡ºåŠ›)

  # Line 192-210: å®‰å…¨ãªSQLå®Ÿè¡Œã¨JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹
  def _execute_sql_directly(self, sql_query: str) -> List[Dict]:
      with psycopg2.connect(
          self.db_manager.pg_conn_str,
          cursor_factory=psycopg2.extras.RealDictCursor
      ) as conn:
          with conn.cursor() as cursor:
              cursor.execute(sql_query)
              results = cursor.fetchall()
              return [dict(row) for row in results]  # JSONå½¢å¼ã§è¿”å´
            """)

        st.markdown("**MCP (Model Context Protocol)çµŒç”±ã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è‡ªç„¶è¨€èªã§è³ªå•ã—ã¦ãã ã•ã„**")
        
        # MCPã‚µãƒ¼ãƒãƒ¼æƒ…å ±ã‚’è¡¨ç¤º
        with st.expander("ğŸ”— MCPã‚µãƒ¼ãƒãƒ¼æƒ…å ±"):
            st.markdown(f"**PostgreSQL MCPã‚µãƒ¼ãƒãƒ¼**: `{self.db_manager.mcp_server_url}`")
            st.markdown("**ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**: Streamlit UI â†’ OpenAI Responses API â†’ MCP Server â†’ PostgreSQL")
        
        # ã‚¯ã‚¨ãƒªå…¥åŠ›ã‚¨ãƒªã‚¢
        col1, col2 = st.columns([3, 1])
        
        with col1:
            # å€™è£œãŒé¸æŠã•ã‚ŒãŸå ´åˆã€ãã®å€¤ã‚’åˆæœŸå€¤ã¨ã—ã¦ä½¿ç”¨
            initial_value = st.session_state.get('selected_suggestion', '')
            
            # è‡ªç„¶è¨€èªã‚¯ã‚¨ãƒªå…¥åŠ›
            user_query = st.text_input(
                "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:",
                value=initial_value,
                placeholder="ä¾‹: æ±äº¬åœ¨ä½ã®30æ­³ä»¥ä¸Šã®é¡§å®¢ã‚’è¡¨ç¤ºã—ã¦",
                key="query_input"
            )
        
        with col2:
            execute_button = st.button("ğŸ” å®Ÿè¡Œ", type="primary")
        
        # ã‚¯ã‚¨ãƒªå€™è£œã®è¡¨ç¤º
        st.markdown("### ğŸ’¡ ã‚¯ã‚¨ãƒªå€™è£œ")
        suggestions = self.get_query_suggestions()
        
        # å€™è£œã‚’3åˆ—ã§è¡¨ç¤º
        cols = st.columns(3)
        for i, suggestion in enumerate(suggestions):
            with cols[i % 3]:
                if st.button(suggestion, key=f"suggestion_{i}"):
                    # å€™è£œã‚’é¸æŠã—ã¦ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›æ¬„ã«è¨­å®šï¼ˆå®Ÿè¡Œã¯ã—ãªã„ï¼‰
                    st.session_state.selected_suggestion = suggestion
                    st.rerun()
        
        # ã‚¯ã‚¨ãƒªå®Ÿè¡Œï¼ˆå®Ÿè¡Œãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚ã®ã¿ï¼‰
        if execute_button and user_query:
            self.execute_mcp_query(user_query)
        elif execute_button and not user_query:
            st.warning("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        
        # çµæœè¡¨ç¤º
        self.display_results()
    
    def execute_mcp_query(self, user_query: str):
        """MCPçµŒç”±ã§è‡ªç„¶è¨€èªã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œ"""
        st.write(f"ğŸ” **å®Ÿè¡Œä¸­ã®ã‚¯ã‚¨ãƒª**: {user_query}")  # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
        
        with st.spinner("ğŸ¤– MCPã‚µãƒ¼ãƒãƒ¼çµŒç”±ã§ã‚¯ã‚¨ãƒªå®Ÿè¡Œä¸­..."):
            # MCPã‚¯ã‚¨ãƒªå®Ÿè¡Œ
            success, results, response_message = self.query_processor.execute_mcp_query(
                user_query, 
                st.session_state.selected_model
            )
            
            if not success:
                st.error(f"MCPã‚¯ã‚¨ãƒªå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {response_message}")
                return
            
            st.success("MCPçµŒç”±ã§ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸï¼")
            
            # MCPã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã®å¿œç­”ã‚’è¡¨ç¤º
            with st.expander("ğŸ¤– MCPã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã®å¿œç­”", expanded=True):
                st.markdown(response_message)
            
            # çµæœã‚’ä¿å­˜
            st.session_state.current_results = results
            st.session_state.current_explanation = response_message
            st.session_state.query_history.append((user_query, "MCPçµŒç”±"))
    
    def display_results(self):
        """çµæœã®è¡¨ç¤º"""
        if st.session_state.current_results is None:
            return
        
        results = st.session_state.current_results
        
        st.markdown("---")
        st.subheader("ğŸ“Š æ¤œç´¢çµæœ")
        
        # AI ã«ã‚ˆã‚‹èª¬æ˜
        if st.session_state.current_explanation:
            st.info(f"ğŸ¤– **AIåˆ†æ**: {st.session_state.current_explanation}")
        
        if not results:
            st.warning("æ¤œç´¢çµæœãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ è¡¨ç¤º
        df = pd.DataFrame(results)
        st.dataframe(df, use_container_width=True)
        
        # ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–ï¼ˆæ•°å€¤ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆï¼‰
        numeric_columns = df.select_dtypes(include=['int64', 'float64']).columns
        if len(numeric_columns) > 0:
            st.subheader("ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–")
            
            # ã‚°ãƒ©ãƒ•ã‚¿ã‚¤ãƒ—é¸æŠ
            chart_type = st.selectbox(
                "ã‚°ãƒ©ãƒ•ã®ç¨®é¡ã‚’é¸æŠ:",
                ["æ£’ã‚°ãƒ©ãƒ•", "æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•", "å††ã‚°ãƒ©ãƒ•", "æ•£å¸ƒå›³"]
            )
            
            if chart_type == "æ£’ã‚°ãƒ©ãƒ•" and len(df.columns) >= 2:
                x_col = st.selectbox("Xè»¸:", df.columns, index=0)
                y_col = st.selectbox("Yè»¸:", numeric_columns, index=0)
                fig = px.bar(df, x=x_col, y=y_col)
                st.plotly_chart(fig, use_container_width=True)
            
            elif chart_type == "å††ã‚°ãƒ©ãƒ•" and len(numeric_columns) > 0:
                values_col = st.selectbox("å€¤:", numeric_columns)
                names_col = st.selectbox("ãƒ©ãƒ™ãƒ«:", df.columns)
                fig = px.pie(df, values=values_col, names=names_col)
                st.plotly_chart(fig, use_container_width=True)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        csv = df.to_csv(index=False, encoding='utf-8')
        st.download_button(
            label="ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv,
            file_name=f"query_results_{int(time.time())}.csv",
            mime="text/csv"
        )
    
    def run(self):
        """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"""
        st.set_page_config(
            page_title="MCPçµŒç”±PostgreSQLã‚¢ã‚¯ã‚»ã‚¹",
            page_icon="ğŸ—£ï¸",
            layout="wide",
            initial_sidebar_state="expanded"
        )
        
        # ã‚«ã‚¹ã‚¿ãƒ ã‚¹ã‚¿ã‚¤ãƒ«é©ç”¨
        st.markdown("""
        <style>
        .stAlert > div {
            padding-top: 10px;
            padding-bottom: 10px;
        }
        .stButton > button {
            width: 100%;
        }
        </style>
        """, unsafe_allow_html=True)
        
        # PostgreSQLæ¥ç¶šçŠ¶æ…‹è¡¨ç¤ºï¼ˆMCPãƒ‡ãƒ¢ç”¨ï¼‰
        mcp_status = self._check_mcp_server_status()
        if not mcp_status:
            st.error("âš ï¸ PostgreSQLãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶šã§ãã¾ã›ã‚“")
            st.info("ğŸ’¡ **è§£æ±ºæ–¹æ³•**:\n1. `docker-compose -f docker-compose/docker-compose.mcp-demo.yml up -d postgres` ã§PostgreSQLã‚’èµ·å‹•\n2. ç’°å¢ƒå¤‰æ•° `PG_CONN_STR` ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        
        # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã¨ãƒ¡ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
        self.create_sidebar()
        self.create_main_interface()
    
    def _check_mcp_server_status(self) -> bool:
        """PostgreSQLæ¥ç¶šãƒã‚§ãƒƒã‚¯ (MCPä»£æ›¿ãƒ‡ãƒ¢)"""
        try:
            with psycopg2.connect(self.db_manager.pg_conn_str, connect_timeout=3) as conn:
                with conn.cursor() as cursor:
                    cursor.execute("SELECT 1;")
                    return cursor.fetchone() is not None
        except Exception as e:
            logger.error(f"PostgreSQL connection check failed: {e}")
            return False


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    try:
        app = NaturalLanguageDBInterface()
        app.run()
    except Exception as e:
        st.error(f"ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        logger.error(f"Application error: {e}")


if __name__ == "__main__":
    main()