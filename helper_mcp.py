# helper_mcp.py
# MCPï¼ˆModel Context Protocolï¼‰é–¢é€£ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã¨ã‚¯ãƒ©ã‚¹
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†ã€UIç®¡ç†ã€ãƒšãƒ¼ã‚¸ç®¡ç†ã‚’å«ã‚€

import streamlit as st
import redis
import psycopg2
import sqlalchemy
import requests
import pandas as pd
import json
import time
import traceback
import os
from datetime import datetime
from typing import Dict, Any, List, Optional
from abc import ABC, abstractmethod

# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ç¢ºèª
try:
    import requests
except ImportError:
    st.error("requests ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ã§ã™: pip install requests")

try:
    import pandas as pd
except ImportError:
    st.error("pandas ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒå¿…è¦ã§ã™: pip install pandas")


# ==================================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# ==================================================
def safe_get_secret(key: str, default: Any = None) -> Any:
    """Streamlit secretsã‹ã‚‰å®‰å…¨ã«å€¤ã‚’å–å¾—"""
    try:
        return st.secrets.get(key, default)
    except Exception:
        # secrets.toml ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ç’°å¢ƒå¤‰æ•°ã‚’ä½¿ç”¨
        return os.getenv(key, default)


def safe_format_number(value: Any, use_comma: bool = True) -> str:
    """æ•°å€¤ã‚’å®‰å…¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    try:
        if value is None:
            return "0"

        # æ•°å€¤å‹ã«å¤‰æ›ã‚’è©¦è¡Œ
        if isinstance(value, (int, float)):
            num_value = value
        else:
            # æ–‡å­—åˆ—ã‹ã‚‰æ•°å€¤ã¸ã®å¤‰æ›ã‚’è©¦è¡Œ
            num_value = float(value)

        # ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        if use_comma:
            # å°æ•°ç‚¹ä»¥ä¸‹ãŒã‚ã‚‹å ´åˆã®å‡¦ç†
            if isinstance(num_value, float) and num_value != int(num_value):
                return f"{num_value:,.0f}"
            else:
                return f"{int(num_value):,}"
        else:
            return str(int(num_value))

    except (ValueError, TypeError):
        # å¤‰æ›ã«å¤±æ•—ã—ãŸå ´åˆã¯æ–‡å­—åˆ—ã¨ã—ã¦è¿”ã™
        return str(value) if value is not None else "N/A"


def safe_format_metric(label: str, value: Any, suffix: str = "", prefix: str = "", use_comma: bool = True) -> None:
    """Streamlitãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å®‰å…¨ã«è¡¨ç¤º"""
    try:
        formatted_value = safe_format_number(value, use_comma)
        display_value = f"{prefix}{formatted_value}{suffix}"
        st.metric(label, display_value)
    except Exception as e:
        st.metric(label, f"ã‚¨ãƒ©ãƒ¼: {e}")


# ==================================================
# è¨­å®šã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
# ==================================================
class MCPSessionManager:
    """MCPã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†"""

    @staticmethod
    def init_session():
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–"""
        if 'messages' not in st.session_state:
            st.session_state.messages = []
        if 'selected_tab_index' not in st.session_state:
            st.session_state.selected_tab_index = 0
        if 'auto_process_question' not in st.session_state:
            st.session_state.auto_process_question = False
        if 'server_status_cache' not in st.session_state:
            st.session_state.server_status_cache = {}
        if 'last_status_check' not in st.session_state:
            st.session_state.last_status_check = 0


# ==================================================
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†ã‚¯ãƒ©ã‚¹ç¾¤
# ==================================================
class DatabaseManager(ABC):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†ã®åŸºåº•ã‚¯ãƒ©ã‚¹"""

    def __init__(self, name: str):
        self.name = name

    @abstractmethod
    def check_connection(self) -> Dict[str, str]:
        """æ¥ç¶šçŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯"""
        pass

    @abstractmethod
    def get_data_summary(self) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿ã®æ¦‚è¦ã‚’å–å¾—"""
        pass


class RedisManager(DatabaseManager):
    """Redisç®¡ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        super().__init__("Redis")
        self.host = safe_get_secret('REDIS_HOST', 'localhost')
        self.port = int(safe_get_secret('REDIS_PORT', 6379))
        self.db = int(safe_get_secret('REDIS_DB', 0))

    def check_connection(self) -> Dict[str, str]:
        """Redisæ¥ç¶šçŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯"""
        try:
            r = redis.Redis(host=self.host, port=self.port, db=self.db, socket_connect_timeout=3)
            r.ping()
            return {"status": "ğŸŸ¢ æ¥ç¶šOK", "details": "æ­£å¸¸"}
        except Exception as e:
            return {"status": f"ğŸ”´ æ¥ç¶šNG", "details": str(e)[:50]}

    def get_data_summary(self) -> Dict[str, Any]:
        """Redisãƒ‡ãƒ¼ã‚¿ã®æ¦‚è¦å–å¾—"""
        try:
            r = redis.Redis(host=self.host, port=self.port, db=self.db, decode_responses=True)

            # ã‚­ãƒ¼æ•°ã‚’å®‰å…¨ã«å–å¾—
            count = 0
            for _ in r.scan_iter():
                count += 1
                if count > 1000:
                    return {"key_count": f"{count}+", "status": "partial"}

            return {
                "key_count"    : str(count),
                "status"       : "complete",
                "session_count": len(r.keys('session:*')),
                "counter_count": len(r.keys('counter:*'))
            }
        except Exception:
            return {"key_count": "?", "status": "error"}

    def get_detailed_data(self) -> Dict[str, Any]:
        """Redisè©³ç´°ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        try:
            r = redis.Redis(host=self.host, port=self.port, db=self.db, decode_responses=True)

            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿
            session_keys = list(r.scan_iter('session:*'))
            session_data = []
            for key in sorted(session_keys):
                data = r.hgetall(key)
                data['session_key'] = key
                session_data.append(data)

            # ã‚«ã‚¦ãƒ³ã‚¿ãƒ‡ãƒ¼ã‚¿
            counter_keys = list(r.scan_iter('counter:*'))
            counter_data = {}
            for key in sorted(counter_keys):
                counter_data[key.replace('counter:', '')] = r.get(key)

            # ãã®ä»–ã®ãƒ‡ãƒ¼ã‚¿
            categories = list(r.smembers('categories:all'))
            search_history = r.lrange('search:recent', 0, -1)

            return {
                "sessions"      : session_data,
                "counters"      : counter_data,
                "categories"    : categories,
                "search_history": search_history
            }
        except Exception as e:
            st.error(f"Redisè©³ç´°ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}

# -----------------------------------------
# PostgreSQLManager(DatabaseManager)
# -----------------------------------------
class PostgreSQLManager(DatabaseManager):
    """PostgreSQLç®¡ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        super().__init__("PostgreSQL")
        # secrets.toml ãŒå­˜åœ¨ã—ãªã„å ´åˆã®ã‚¨ãƒ©ãƒ¼ã‚’å›é¿
        self.conn_str = safe_get_secret('PG_CONN_STR', os.getenv('PG_CONN_STR'))

    def check_connection(self) -> Dict[str, str]:
        """PostgreSQLæ¥ç¶šçŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯"""
        if not self.conn_str:
            return {"status": "ğŸ”´ æ¥ç¶šNG", "details": "æ¥ç¶šæ–‡å­—åˆ—ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"}

        try:
            conn = psycopg2.connect(self.conn_str, connect_timeout=3)
            conn.close()
            return {"status": "ğŸŸ¢ æ¥ç¶šOK", "details": "æ­£å¸¸"}
        except Exception as e:
            return {"status": f"ğŸ”´ æ¥ç¶šNG", "details": str(e)[:50]}

    def get_data_summary(self) -> Dict[str, Any]:
        """PostgreSQLãƒ‡ãƒ¼ã‚¿ã®æ¦‚è¦å–å¾—"""
        if not self.conn_str:
            return {"table_count": "?", "status": "error", "message": "æ¥ç¶šæ–‡å­—åˆ—æœªè¨­å®š"}

        try:
            engine = sqlalchemy.create_engine(self.conn_str)

            # ãƒ†ãƒ¼ãƒ–ãƒ«æ•°ã¨åŸºæœ¬çµ±è¨ˆ
            customers = pd.read_sql("SELECT COUNT(*) as count FROM customers", engine).iloc[0]['count']
            orders = pd.read_sql("SELECT COUNT(*) as count FROM orders", engine).iloc[0]['count']
            products = pd.read_sql("SELECT COUNT(*) as count FROM products", engine).iloc[0]['count']

            engine.dispose()
            return {
                "table_count": 3,
                "customers"  : customers,
                "orders"     : orders,
                "products"   : products,
                "status"     : "complete"
            }
        except Exception:
            return {"table_count": "?", "status": "error"}

    def get_detailed_data(self) -> Dict[str, Any]:
        """PostgreSQLè©³ç´°ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        if not self.conn_str:
            st.error("PostgreSQLæ¥ç¶šæ–‡å­—åˆ—ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return {}

        try:
            engine = sqlalchemy.create_engine(self.conn_str)

            # å„ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ‡ãƒ¼ã‚¿
            customers = pd.read_sql("SELECT * FROM customers ORDER BY id LIMIT 10", engine)
            orders = pd.read_sql("""
                                 SELECT o.*, c.name as customer_name
                                 FROM orders o
                                          JOIN customers c ON o.customer_id = c.id
                                 ORDER BY o.order_date DESC
                                 LIMIT 10
                                 """, engine)
            products = pd.read_sql("SELECT * FROM products ORDER BY id", engine)

            # çµ±è¨ˆæƒ…å ±
            total_sales = pd.read_sql("SELECT SUM(price * quantity) as total FROM orders", engine).iloc[0]['total']

            engine.dispose()
            return {
                "customers"  : customers,
                "orders"     : orders,
                "products"   : products,
                "total_sales": total_sales
            }
        except Exception as e:
            st.error(f"PostgreSQLè©³ç´°ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {}


class ElasticsearchManager(DatabaseManager):
    """Elasticsearchç®¡ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        super().__init__("Elasticsearch")
        self.url = safe_get_secret('ELASTIC_URL', os.getenv('ELASTIC_URL', 'http://localhost:9200'))

    def check_connection(self) -> Dict[str, str]:
        """Elasticsearchæ¥ç¶šçŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯"""
        try:
            response = requests.get(f'{self.url}/_cluster/health', timeout=3)
            if response.status_code == 200:
                return {"status": "ğŸŸ¢ æ¥ç¶šOK", "details": "æ­£å¸¸"}
            else:
                return {"status": f"ğŸ”´ æ¥ç¶šNG", "details": f"Status: {response.status_code}"}
        except Exception as e:
            return {"status": f"ğŸ”´ æ¥ç¶šNG", "details": str(e)[:50]}

    def get_data_summary(self) -> Dict[str, Any]:
        """Elasticsearchãƒ‡ãƒ¼ã‚¿ã®æ¦‚è¦å–å¾—"""
        try:
            response = requests.get(f'{self.url}/blog_articles/_count', timeout=3)
            if response.status_code == 200:
                count = response.json()['count']
                return {"document_count": count, "status": "complete"}
            else:
                return {"document_count": "?", "status": "error"}
        except Exception:
            return {"document_count": "?", "status": "error"}

    def search_articles(self, term: str, field: str = "å…¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰") -> List[Dict]:
        """è¨˜äº‹æ¤œç´¢"""
        try:
            if field == "å…¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰":
                query = {
                    "query"    : {
                        "multi_match": {
                            "query" : term,
                            "fields": ["title^2", "content", "category", "author"]
                        }
                    },
                    "highlight": {
                        "fields": {
                            "title"  : {},
                            "content": {}
                        }
                    }
                }
            else:
                query = {
                    "query"    : {
                        "match": {
                            field: term
                        }
                    },
                    "highlight": {
                        "fields": {
                            field: {}
                        }
                    }
                }

            response = requests.post(
                f'{self.url}/blog_articles/_search',
                json=query,
                headers={'Content-Type': 'application/json'}
            )

            if response.status_code == 200:
                return response.json()['hits']['hits']
            return []
        except Exception as e:
            st.error(f"Elasticsearchæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []


class QdrantManager(DatabaseManager):
    """Qdrantç®¡ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        super().__init__("Qdrant")
        self.url = safe_get_secret('QDRANT_URL', os.getenv('QDRANT_URL', 'http://localhost:6333'))

    def check_connection(self) -> Dict[str, str]:
        """Qdrantæ¥ç¶šçŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯"""
        try:
            response = requests.get(f'{self.url}/', timeout=3)
            if response.status_code == 200:
                return {"status": "ğŸŸ¢ æ¥ç¶šOK", "details": "æ­£å¸¸"}
            else:
                return {"status": f"ğŸ”´ æ¥ç¶šNG", "details": f"Status: {response.status_code}"}
        except Exception as e:
            return {"status": f"ğŸ”´ æ¥ç¶šNG", "details": str(e)[:50]}

    def get_data_summary(self) -> Dict[str, Any]:
        """Qdrantãƒ‡ãƒ¼ã‚¿ã®æ¦‚è¦å–å¾—"""
        try:
            response = requests.get(f'{self.url}/collections', timeout=3)
            if response.status_code == 200:
                collections = response.json().get('result', {}).get('collections', [])
                return {
                    "collection_count": len(collections),
                    "collections"     : [col['name'] for col in collections],
                    "status"          : "complete"
                }
            return {"collection_count": "?", "status": "error"}
        except Exception:
            return {"collection_count": "?", "status": "error"}


# ==================================================
# ã‚µãƒ¼ãƒãƒ¼çŠ¶æ…‹ç®¡ç†
# ==================================================
class ServerStatusManager:
    """å…¨ã‚µãƒ¼ãƒãƒ¼ã®çŠ¶æ…‹ç®¡ç†"""

    def __init__(self):
        self.managers = {
            'Redis'        : RedisManager(),
            'PostgreSQL'   : PostgreSQLManager(),
            'Elasticsearch': ElasticsearchManager(),
            'Qdrant'       : QdrantManager()
        }

    @st.cache_data(ttl=30)
    def check_all_servers(_self) -> Dict[str, Dict[str, str]]:
        """å…¨ã‚µãƒ¼ãƒãƒ¼ã®çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰"""
        status = {}
        for name, manager in _self.managers.items():
            status[name] = manager.check_connection()
        return status

    def get_connected_count(self) -> int:
        """æ¥ç¶šæ¸ˆã¿ã‚µãƒ¼ãƒãƒ¼æ•°ã‚’å–å¾—"""
        status = self.check_all_servers()
        return sum(1 for s in status.values() if "ğŸŸ¢" in s["status"])

    def get_manager(self, name: str) -> Optional[DatabaseManager]:
        """æŒ‡å®šã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’å–å¾—"""
        return self.managers.get(name)


# ==================================================
# UIç®¡ç†ã‚¯ãƒ©ã‚¹
# ==================================================
class SidebarManager:
    """ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ç®¡ç†"""

    def __init__(self, status_manager: ServerStatusManager):
        self.status_manager = status_manager

    def render_server_status(self):
        """ã‚µãƒ¼ãƒãƒ¼çŠ¶æ…‹ã®è¡¨ç¤º"""
        st.sidebar.header("ğŸ“Š MCP ã‚µãƒ¼ãƒãƒ¼çŠ¶æ…‹")

        if st.sidebar.button("ğŸ”„ çŠ¶æ…‹æ›´æ–°"):
            st.cache_data.clear()

        status = self.status_manager.check_all_servers()
        for server, state in status.items():
            st.sidebar.markdown(f"**{server}**: {state['status']}")

        connected_count = self.status_manager.get_connected_count()
        st.sidebar.markdown(f"**æ¥ç¶šæ¸ˆã¿**: {connected_count}/4 ã‚µãƒ¼ãƒãƒ¼")

    def render_quick_actions(self):
        """ã‚¯ã‚¤ãƒƒã‚¯ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®è¡¨ç¤º"""
        st.sidebar.markdown("---")
        st.sidebar.header("âš¡ ã‚¯ã‚¤ãƒƒã‚¯ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")

        if st.sidebar.button("ğŸš€ Dockerèµ·å‹•"):
            st.sidebar.code("docker-compose -f docker-compose.mcp-demo.yml up -d")

        if st.sidebar.button("ğŸ“Š ãƒ‡ãƒ¼ã‚¿å†æŠ•å…¥"):
            st.sidebar.code("uv run python scripts/setup_test_data.py")

    def render_navigation(self, tab_names: List[str]) -> int:
        """ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ã®è¡¨ç¤º"""
        st.sidebar.markdown("---")
        st.sidebar.header("ğŸ“‹ ãƒšãƒ¼ã‚¸é¸æŠ")

        current_tab = st.session_state.selected_tab_index

        for i, tab_name in enumerate(tab_names):
            # ç¾åœ¨ã®ã‚¿ãƒ–ã‹ã©ã†ã‹ã§è¡¨ç¤ºã‚’å¤‰ãˆã‚‹
            if i == current_tab:
                st.sidebar.markdown(f"**â–¶ {tab_name}**")
            else:
                if st.sidebar.button(tab_name, key=f"tab_btn_{i}"):
                    st.session_state.selected_tab_index = i
                    st.rerun()

        return current_tab


# ==================================================
# ãƒšãƒ¼ã‚¸ç®¡ç†ã‚¯ãƒ©ã‚¹ç¾¤
# ==================================================
class PageManager(ABC):
    """ãƒšãƒ¼ã‚¸ç®¡ç†ã®åŸºåº•ã‚¯ãƒ©ã‚¹"""

    def __init__(self, name: str, status_manager: ServerStatusManager):
        self.name = name
        self.status_manager = status_manager

    @abstractmethod
    def render(self):
        """ãƒšãƒ¼ã‚¸ã®æç”»"""
        pass


class DataViewPage(PageManager):
    """ãƒ‡ãƒ¼ã‚¿ç¢ºèªãƒšãƒ¼ã‚¸"""

    def render(self):
        st.write("ğŸ“Š æŠ•å…¥ã•ã‚ŒãŸãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª")

        # ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ã‚«ãƒ¼ãƒ‰
        self._render_summary_metrics()

        st.markdown("---")

        # ãƒ‡ãƒ¼ã‚¿è©³ç´°è¡¨ç¤º
        self._render_detailed_data()

    def _render_summary_metrics(self):
        """æ¦‚è¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¡¨ç¤º"""
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            redis_manager = self.status_manager.get_manager('Redis')
            redis_summary = redis_manager.get_data_summary()
            st.metric(
                label="Redis Keys",
                value=redis_summary.get('key_count', '?'),
                help="Redisã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã‚­ãƒ¼ã®ç·æ•°"
            )

        with col2:
            pg_manager = self.status_manager.get_manager('PostgreSQL')
            pg_summary = pg_manager.get_data_summary()
            st.metric(
                label="PostgreSQL Tables",
                value=pg_summary.get('table_count', '?'),
                help="customers, orders, products"
            )

        with col3:
            es_manager = self.status_manager.get_manager('Elasticsearch')
            es_summary = es_manager.get_data_summary()
            st.metric(
                label="ES Documents",
                value=es_summary.get('document_count', '?'),
                help="ãƒ–ãƒ­ã‚°è¨˜äº‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°"
            )

        with col4:
            qdrant_manager = self.status_manager.get_manager('Qdrant')
            qdrant_summary = qdrant_manager.get_data_summary()
            st.metric(
                label="Qdrant Collections",
                value=qdrant_summary.get('collection_count', '?'),
                help="ãƒ™ã‚¯ãƒˆãƒ«ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ•°"
            )

    def _render_detailed_data(self):
        """è©³ç´°ãƒ‡ãƒ¼ã‚¿ã®è¡¨ç¤º"""
        col1, col2 = st.columns(2)

        with col1:
            self._render_redis_details()

        with col2:
            self._render_postgresql_details()

        # ä»–ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚‚åŒæ§˜ã«
        st.markdown("---")
        self._render_elasticsearch_details()
        self._render_qdrant_details()

    def _render_redis_details(self):
        """Redisè©³ç´°è¡¨ç¤º"""
        st.subheader("ğŸ”´ Redis ãƒ‡ãƒ¼ã‚¿")
        if st.button("Redis ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º", key="show_redis"):
            redis_manager = self.status_manager.get_manager('Redis')
            with st.spinner("Redisãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­..."):
                data = redis_manager.get_detailed_data()

                if data.get('sessions'):
                    st.write("**ğŸ”‘ ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿:**")
                    df_sessions = pd.DataFrame(data['sessions'])
                    st.dataframe(df_sessions, use_container_width=True)

                if data.get('counters'):
                    st.write("**ğŸ“Š ã‚«ã‚¦ãƒ³ã‚¿ãƒ‡ãƒ¼ã‚¿:**")
                    counter_cols = st.columns(2)
                    for i, (key, value) in enumerate(data['counters'].items()):
                        with counter_cols[i % 2]:
                            st.metric(key.replace('_', ' ').title(), value)

    def _render_postgresql_details(self):
        """PostgreSQLè©³ç´°è¡¨ç¤º"""
        st.subheader("ğŸŸ¦ PostgreSQL ãƒ‡ãƒ¼ã‚¿")
        if st.button("PostgreSQL ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º", key="show_postgres"):
            pg_manager = self.status_manager.get_manager('PostgreSQL')
            with st.spinner("PostgreSQLãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­..."):
                data = pg_manager.get_detailed_data()

                if 'customers' in data:
                    st.write("**ğŸ‘¥ é¡§å®¢ãƒ‡ãƒ¼ã‚¿:**")
                    st.dataframe(data['customers'], use_container_width=True)

                if 'orders' in data:
                    st.write("**ğŸ›’ æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿:**")
                    st.dataframe(data['orders'], use_container_width=True)

    def _render_elasticsearch_details(self):
        """Elasticsearchè©³ç´°è¡¨ç¤º"""
        st.subheader("ğŸŸ¡ Elasticsearch ãƒ‡ãƒ¼ã‚¿")
        if st.button("Elasticsearch ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º", key="show_elasticsearch"):
            es_manager = self.status_manager.get_manager('Elasticsearch')
            status = es_manager.check_connection()

            if "ğŸŸ¢" in status["status"]:
                with st.spinner("Elasticsearchãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­..."):
                    try:
                        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä¸€è¦§ã‚’å–å¾—
                        response = requests.get(f'{es_manager.url}/_cat/indices?format=json', timeout=5)
                        if response.status_code == 200:
                            indices_data = response.json()

                            st.write("**ğŸ“‹ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä¸€è¦§:**")
                            if indices_data:
                                df_indices = pd.DataFrame(indices_data)
                                # ä¸»è¦ãªåˆ—ã®ã¿è¡¨ç¤º
                                display_columns = ['index', 'docs.count', 'store.size', 'status']
                                available_columns = [col for col in display_columns if col in df_indices.columns]
                                if available_columns:
                                    st.dataframe(df_indices[available_columns], use_container_width=True)
                                else:
                                    st.dataframe(df_indices, use_container_width=True)
                            else:
                                st.info("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

                        # ã‚µãƒ³ãƒ—ãƒ«æ¤œç´¢ï¼ˆblog_articlesã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒã‚ã‚‹å ´åˆï¼‰
                        search_response = requests.get(f'{es_manager.url}/blog_articles/_search?size=5', timeout=5)
                        if search_response.status_code == 200:
                            search_data = search_response.json()
                            hits = search_data.get('hits', {}).get('hits', [])

                            if hits:
                                st.write("**ğŸ“ ã‚µãƒ³ãƒ—ãƒ«è¨˜äº‹ãƒ‡ãƒ¼ã‚¿:**")
                                for i, hit in enumerate(hits, 1):
                                    source = hit.get('_source', {})
                                    with st.expander(f"è¨˜äº‹ {i}: {source.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜')}"):
                                        col1, col2 = st.columns([2, 1])
                                        with col1:
                                            st.write(f"**å†…å®¹:** {source.get('content', 'N/A')}")
                                            st.write(f"**ã‚«ãƒ†ã‚´ãƒª:** {source.get('category', 'N/A')}")
                                        with col2:
                                            st.write(f"**è‘—è€…:** {source.get('author', 'N/A')}")
                                            st.write(f"**é–²è¦§æ•°:** {source.get('view_count', 'N/A')}")
                                            st.write(f"**å…¬é–‹æ—¥:** {source.get('published_date', 'N/A')}")
                            else:
                                st.info("blog_articlesã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                        else:
                            st.warning("blog_articlesã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒå­˜åœ¨ã—ãªã„ã‹ã€ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“")

                    except Exception as e:
                        st.error(f"Elasticsearchè©³ç´°ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            else:
                st.warning("Elasticsearchã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“")
                st.write(f"çŠ¶æ…‹: {status['status']}")
                st.write(f"è©³ç´°: {status['details']}")

    def _render_qdrant_details(self):
        """Qdrantè©³ç´°è¡¨ç¤º"""
        st.subheader("ğŸŸ  Qdrant ãƒ‡ãƒ¼ã‚¿")
        if st.button("Qdrant ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º", key="show_qdrant"):
            qdrant_manager = self.status_manager.get_manager('Qdrant')
            status = qdrant_manager.check_connection()

            if "ğŸŸ¢" in status["status"]:
                with st.spinner("Qdrantãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­..."):
                    try:
                        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§ã‚’å–å¾—
                        response = requests.get(f'{qdrant_manager.url}/collections', timeout=5)
                        if response.status_code == 200:
                            collections_data = response.json()
                            collections = collections_data.get('result', {}).get('collections', [])

                            st.write("**ğŸ“š ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§:**")
                            if collections:
                                collection_info = []
                                for collection in collections:
                                    # å„ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®è©³ç´°ã‚’å–å¾—
                                    detail_response = requests.get(
                                        f'{qdrant_manager.url}/collections/{collection["name"]}',
                                        timeout=5
                                    )
                                    if detail_response.status_code == 200:
                                        detail_data = detail_response.json()
                                        result = detail_data.get('result', {})
                                        config = result.get('config', {})

                                        collection_info.append({
                                            'åå‰'        : collection['name'],
                                            'ãƒ™ã‚¯ãƒˆãƒ«æ•°'  : result.get('points_count', 0),
                                            'ãƒ™ã‚¯ãƒˆãƒ«æ¬¡å…ƒ': config.get('params', {}).get('vectors', {}).get('size',
                                                                                                            'N/A'),
                                            'è·é›¢è¨ˆç®—'    : config.get('params', {}).get('vectors', {}).get('distance',
                                                                                                            'N/A'),
                                            'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'  : result.get('status', 'unknown')
                                        })
                                    else:
                                        collection_info.append({
                                            'åå‰'        : collection['name'],
                                            'ãƒ™ã‚¯ãƒˆãƒ«æ•°'  : 'N/A',
                                            'ãƒ™ã‚¯ãƒˆãƒ«æ¬¡å…ƒ': 'N/A',
                                            'è·é›¢è¨ˆç®—'    : 'N/A',
                                            'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'  : 'unknown'
                                        })

                                df_collections = pd.DataFrame(collection_info)
                                st.dataframe(df_collections, use_container_width=True)
                            else:
                                st.info("ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

                        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆæœ€åˆã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰ï¼‰
                        if collections:
                            collection_name = collections[0]['name']

                            # ãƒã‚¤ãƒ³ãƒˆã‚’å–å¾—
                            points_response = requests.post(
                                f'{qdrant_manager.url}/collections/{collection_name}/points/scroll',
                                json={"limit": 5, "with_payload": True, "with_vector": False},
                                headers={'Content-Type': 'application/json'},
                                timeout=5
                            )

                            if points_response.status_code == 200:
                                points_data = points_response.json()
                                points = points_data.get('result', {}).get('points', [])

                                if points:
                                    st.write(f"**ğŸ” {collection_name} ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿:**")
                                    sample_data = []
                                    for point in points:
                                        payload = point.get('payload', {})
                                        sample_data.append({
                                            'ID': point.get('id', 'N/A'),
                                            **{k: str(v)[:50] + ('...' if len(str(v)) > 50 else '')
                                               for k, v in payload.items()}
                                        })

                                    if sample_data:
                                        df_samples = pd.DataFrame(sample_data)
                                        st.dataframe(df_samples, use_container_width=True)

                        # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æƒ…å ±
                        st.write("**ğŸ¥ ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æƒ…å ±:**")
                        try:
                            cluster_response = requests.get(f'{qdrant_manager.url}/cluster', timeout=5)

                            if cluster_response.status_code == 200:
                                cluster_data = cluster_response.json()
                                result = cluster_data.get('result', {})

                                # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ©Ÿèƒ½ã®çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯
                                cluster_status = result.get('status')

                                if cluster_status == 'disabled':
                                    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ©Ÿèƒ½ãŒç„¡åŠ¹ã®å ´åˆï¼ˆå˜ä¸€ãƒãƒ¼ãƒ‰æ§‹æˆï¼‰
                                    st.info("ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ©Ÿèƒ½ã¯ç„¡åŠ¹ã§ã™ï¼ˆå˜ä¸€ãƒãƒ¼ãƒ‰æ§‹æˆï¼‰")

                                    # Telemetryæƒ…å ±ã‹ã‚‰ä»£æ›¿æƒ…å ±ã‚’å–å¾—
                                    try:
                                        telemetry_response = requests.get(f'{qdrant_manager.url}/telemetry', timeout=5)
                                        if telemetry_response.status_code == 200:
                                            telemetry_data = telemetry_response.json()
                                            telemetry_result = telemetry_data.get('result', {})

                                            col1, col2 = st.columns(2)
                                            with col1:
                                                st.write(f"**ãƒãƒ¼ãƒ‰ID:** {telemetry_result.get('id', 'N/A')}")
                                                collections_count = len(telemetry_result.get('collections', {}))
                                                st.write(f"**ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ•°:** {collections_count}")
                                            with col2:
                                                app_info = telemetry_result.get('app', {})
                                                st.write(f"**ãƒãƒ¼ã‚¸ãƒ§ãƒ³:** {app_info.get('version', 'N/A')}")
                                                st.write(f"**æ§‹æˆãƒ¢ãƒ¼ãƒ‰:** ã‚¹ã‚¿ãƒ³ãƒ‰ã‚¢ãƒ­ãƒ¼ãƒ³")

                                    except Exception as telemetry_error:
                                        st.warning(f"Telemetryæƒ…å ±ã®å–å¾—ã«å¤±æ•—: {telemetry_error}")
                                        st.write("**æ§‹æˆ:** å˜ä¸€ãƒãƒ¼ãƒ‰ï¼ˆè©³ç´°æƒ…å ±å–å¾—ä¸å¯ï¼‰")

                                elif cluster_status == 'enabled' or 'peers' in result:
                                    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ©Ÿèƒ½ãŒæœ‰åŠ¹ã®å ´åˆï¼ˆè¤‡æ•°ãƒãƒ¼ãƒ‰æ§‹æˆï¼‰
                                    col1, col2 = st.columns(2)
                                    with col1:
                                        peers = result.get('peers', [])
                                        st.write(f"**ãƒ”ã‚¢æ•°:** {len(peers)}")
                                        st.write(f"**ãƒ­ãƒ¼ã‚«ãƒ«ãƒ”ã‚¢ID:** {result.get('peer_id', 'N/A')}")
                                    with col2:
                                        consensus_thread = result.get('consensus_thread_status', {})
                                        st.write(f"**ãƒªãƒ¼ãƒ€ãƒ¼:** {consensus_thread.get('is_leader', False)}")
                                        st.write(f"**ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼çŠ¶æ…‹:** {cluster_status or 'æœ‰åŠ¹'}")

                                else:
                                    # ä¸æ˜ãªçŠ¶æ…‹
                                    st.warning(f"ä¸æ˜ãªã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼çŠ¶æ…‹: {cluster_status}")
                                    st.write("**æ§‹æˆ:** ä¸æ˜")

                                # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆå±•é–‹å¯èƒ½ï¼‰
                                with st.expander("ğŸ” è©³ç´°ãªã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æƒ…å ±", expanded=False):
                                    st.json(cluster_data)

                            else:
                                st.warning(f"ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æƒ…å ±ã®å–å¾—ã«å¤±æ•— (Status: {cluster_response.status_code})")

                        except requests.exceptions.RequestException as e:
                            st.warning(f"ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æƒ…å ±ã®å–å¾—ã§ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: {e}")

                    except Exception as e:
                        st.error(f"Qdrantè©³ç´°ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            else:
                st.warning("Qdrantã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“")
                st.write(f"çŠ¶æ…‹: {status['status']}")
                st.write(f"è©³ç´°: {status['details']}")


class AIChatPage(PageManager):
    """AIãƒãƒ£ãƒƒãƒˆãƒšãƒ¼ã‚¸"""

    def render(self):
        st.header("ğŸ¤– AI ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆï¼ˆMCPçµŒç”±ï¼‰")

        # ã‚µãƒ¼ãƒãƒ¼çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯
        if not self._check_servers():
            return

        # API ã‚­ãƒ¼ãƒã‚§ãƒƒã‚¯
        if not self._check_api_key():
            return

        # ã‚µãƒ³ãƒ—ãƒ«è³ªå•
        self._render_sample_questions()

        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´
        self._render_chat_history()

        # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›
        self._handle_chat_input()

    def _check_servers(self) -> bool:
        """ã‚µãƒ¼ãƒãƒ¼çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯"""
        status = self.status_manager.check_all_servers()
        servers_ready = all("ğŸŸ¢" in s["status"] for s in status.values())

        if not servers_ready:
            st.warning("âš ï¸ ä¸€éƒ¨ã®ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚MCPã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã¦ãã ã•ã„ã€‚")
            st.code("""
# MCPã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
docker-compose -f docker-compose.mcp-demo.yml up -d redis-mcp postgres-mcp es-mcp qdrant-mcp
            """)
            return False
        return True

    def _check_api_key(self) -> bool:
        """API ã‚­ãƒ¼ãƒã‚§ãƒƒã‚¯"""
        api_key = safe_get_secret('OPENAI_API_KEY', os.getenv('OPENAI_API_KEY'))
        if not api_key:
            st.error("ğŸ”‘ OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯secrets.tomlã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

            # è¨­å®šæ–¹æ³•ã‚’è¡¨ç¤º
            with st.expander("ğŸ”§ è¨­å®šæ–¹æ³•", expanded=True):
                st.markdown("""
                **æ–¹æ³•1: ç’°å¢ƒå¤‰æ•°ï¼ˆæ¨å¥¨ï¼‰**
                ```bash
                export OPENAI_API_KEY="sk-..."
                ```

                **æ–¹æ³•2: .envãƒ•ã‚¡ã‚¤ãƒ«**
                ```
                OPENAI_API_KEY=sk-...
                ```

                **æ–¹æ³•3: secrets.tomlãƒ•ã‚¡ã‚¤ãƒ«**
                ```toml
                # .streamlit/secrets.toml
                OPENAI_API_KEY = "sk-..."
                ```
                """)
            return False
        return True

    def _render_sample_questions(self):
        """ã‚µãƒ³ãƒ—ãƒ«è³ªå•ã®è¡¨ç¤º"""
        st.subheader("ğŸ’¡ ã‚µãƒ³ãƒ—ãƒ«è³ªå•")
        sample_questions = [
            "Redisã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°ã‚’æ•™ãˆã¦",
            "PostgreSQLã®é¡§å®¢ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰æ±äº¬åœ¨ä½ã®é¡§å®¢ã‚’æ¤œç´¢ã—ã¦",
            "Elasticsearchã§ã€ŒPythonã€ã«é–¢ã™ã‚‹è¨˜äº‹ã‚’æ¤œç´¢ã—ã¦",
            "Qdrantã®å•†å“ãƒ™ã‚¯ãƒˆãƒ«ã‹ã‚‰é¡ä¼¼å•†å“ã‚’è¦‹ã¤ã‘ã¦",
            "ä»Šæ—¥ã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã¦"
        ]

        selected_question = st.selectbox(
            "è³ªå•ã‚’é¸æŠï¼ˆã¾ãŸã¯ä¸‹ã®ãƒãƒ£ãƒƒãƒˆã«ç›´æ¥å…¥åŠ›ï¼‰:",
            ["é¸æŠã—ã¦ãã ã•ã„..."] + sample_questions,
            key="question_selector"
        )

        if selected_question != "é¸æŠã—ã¦ãã ã•ã„..." and st.button("ã“ã®è³ªå•ã‚’ä½¿ç”¨", key="use_question_btn"):
            st.session_state.messages.append({"role": "user", "content": selected_question})
            st.session_state.auto_process_question = True
            st.session_state.selected_tab_index = 1  # AIãƒãƒ£ãƒƒãƒˆãƒšãƒ¼ã‚¸ã‚’ç¶­æŒ
            st.rerun()

    def _render_chat_history(self):
        """ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º"""
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.write(message["content"])

    def _handle_chat_input(self):
        """ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ã®å‡¦ç†"""
        prompt = st.chat_input("ä½•ã‹è³ªå•ã—ã¦ãã ã•ã„")

        if st.session_state.auto_process_question or prompt:
            if st.session_state.auto_process_question:
                st.session_state.auto_process_question = False
                if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
                    current_prompt = st.session_state.messages[-1]["content"]
                else:
                    current_prompt = None
            else:
                current_prompt = prompt
                st.session_state.messages.append({"role": "user", "content": prompt})
                with st.chat_message("user"):
                    st.write(prompt)

            if current_prompt:
                self._generate_ai_response(current_prompt)

        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚¯ãƒªã‚¢
        if st.button("ğŸ—‘ï¸ ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢", key="clear_chat"):
            st.session_state.messages = []
            st.rerun()

    def _generate_ai_response(self, prompt: str):
        """AIå¿œç­”ã®ç”Ÿæˆ"""
        with st.chat_message("assistant"):
            response_placeholder = st.empty()

            try:
                with st.spinner("AI ãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
                    # å®Ÿéš›ã®MCPå‡¦ç†ã¯ã“ã“ã«å®Ÿè£…
                    response_text = self._create_demo_response(prompt)

                    # ã‚¿ã‚¤ãƒ—ãƒ©ã‚¤ã‚¿ãƒ¼åŠ¹æœ
                    full_response = ""
                    for word in response_text.split():
                        full_response += word + " "
                        response_placeholder.markdown(full_response + "â–Œ")
                        time.sleep(0.05)

                    response_placeholder.markdown(response_text)
                    st.session_state.messages.append({"role": "assistant", "content": response_text})

            except Exception as e:
                error_msg = f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
                response_placeholder.error(error_msg)
                st.session_state.messages.append({"role": "assistant", "content": error_msg})

    def _create_demo_response(self, prompt: str) -> str:
        """ãƒ‡ãƒ¢ç”¨ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”Ÿæˆ"""
        return f"""
ğŸ¤– **AI Assistant Response**

è³ªå•: "{prompt}"

ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ç¾åœ¨MCPã‚µãƒ¼ãƒãƒ¼ã¨ã®é€£æºæ©Ÿèƒ½ã¯é–‹ç™ºä¸­ã§ã™ã€‚
ä»£ã‚ã‚Šã«ã€åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦èª¬æ˜ã„ãŸã—ã¾ã™ï¼š

**ğŸ“Š åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿:**
- **Redis**: ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ã€ã‚«ã‚¦ãƒ³ã‚¿ã€æ¤œç´¢å±¥æ­´
- **PostgreSQL**: é¡§å®¢æƒ…å ±ã€æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã€å•†å“ã‚«ã‚¿ãƒ­ã‚°
- **Elasticsearch**: ãƒ–ãƒ­ã‚°è¨˜äº‹ã€å…¨æ–‡æ¤œç´¢
- **Qdrant**: å•†å“ãƒ™ã‚¯ãƒˆãƒ«ã€æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ 

**ğŸ’¡ ç¾åœ¨ã§ãã‚‹ã“ã¨:**
- "ğŸ“Š ç›´æ¥ã‚¯ã‚¨ãƒª" ã‚¿ãƒ–ã§å„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹
- "ğŸ” ãƒ‡ãƒ¼ã‚¿ç¢ºèª" ã‚¿ãƒ–ã§ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
        """


class DataAnalysisPage(PageManager):
    """ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒšãƒ¼ã‚¸"""

    def render(self):
        st.header("ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿åˆ†æã¨ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

        # å¿…è¦ãªã‚µãƒ¼ãƒãƒ¼ã®ç¢ºèª
        status = self.status_manager.check_all_servers()
        required_servers = ['PostgreSQL', 'Redis']
        servers_ready = all("ğŸŸ¢" in status[server]["status"] for server in required_servers)

        if not servers_ready:
            st.warning("ãƒ‡ãƒ¼ã‚¿åˆ†æã«ã¯ PostgreSQL ã¨ Redis ã®æ¥ç¶šãŒå¿…è¦ã§ã™")
            return

        try:
            self._render_sales_analysis()
            self._render_redis_statistics()
        except Exception as e:
            st.error(f"ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¨ãƒ©ãƒ¼: {e}")

    def _render_sales_analysis(self):
        """å£²ä¸Šåˆ†æ"""
        st.subheader("ğŸ’° å£²ä¸Šåˆ†æ")

        engine = sqlalchemy.create_engine(os.getenv('PG_CONN_STR'))

        col1, col2, col3 = st.columns(3)

        # ç·å£²ä¸Š
        total_sales = pd.read_sql("SELECT SUM(price * quantity) as total FROM orders", engine).iloc[0]['total']
        with col1:
            safe_format_metric("ç·å£²ä¸Š", total_sales, prefix="Â¥")

        # å¹³å‡æ³¨æ–‡ä¾¡æ ¼
        avg_order = pd.read_sql("SELECT AVG(price * quantity) as avg FROM orders", engine).iloc[0]['avg']
        with col2:
            safe_format_metric("å¹³å‡æ³¨æ–‡ä¾¡æ ¼", avg_order, prefix="Â¥")

        # æ³¨æ–‡æ•°
        order_count = pd.read_sql("SELECT COUNT(*) as count FROM orders", engine).iloc[0]['count']
        with col3:
            safe_format_metric("ç·æ³¨æ–‡æ•°", order_count, suffix="ä»¶", use_comma=False)

        engine.dispose()

    def _render_redis_statistics(self):
        """Redisçµ±è¨ˆ"""
        st.subheader("ğŸ”´ Redis çµ±è¨ˆ")

        try:
            r = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)

            col1, col2, col3 = st.columns(3)

            with col1:
                active_sessions = len(r.keys('session:*'))
                safe_format_metric("ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚»ãƒƒã‚·ãƒ§ãƒ³", active_sessions, use_comma=False)

            with col2:
                page_views = r.get('counter:page_views') or 0
                safe_format_metric("ãƒšãƒ¼ã‚¸ãƒ“ãƒ¥ãƒ¼", page_views)

            with col3:
                search_count = r.llen('search:recent')
                safe_format_metric("æ¤œç´¢å±¥æ­´æ•°", search_count, use_comma=False)

            # Redisè©³ç´°çµ±è¨ˆ
            st.write("**Redisè©³ç´°çµ±è¨ˆ**")

            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼ˆinfo commandã®çµæœã‚’ãƒ‘ãƒ¼ã‚¹ï¼‰
            redis_info = r.info()

            col1, col2, col3, col4 = st.columns(4)

            with col1:
                used_memory = redis_info.get('used_memory_human', 'N/A')
                st.metric("ä½¿ç”¨ãƒ¡ãƒ¢ãƒª", used_memory)

            with col2:
                connected_clients = redis_info.get('connected_clients', 0)
                safe_format_metric("æ¥ç¶šã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ•°", connected_clients, use_comma=False)

            with col3:
                total_commands = redis_info.get('total_commands_processed', 0)
                safe_format_metric("ç·ã‚³ãƒãƒ³ãƒ‰æ•°", total_commands)

            with col4:
                uptime_days = redis_info.get('uptime_in_days', 0)
                safe_format_metric("ç¨¼åƒæ—¥æ•°", uptime_days, "æ—¥", use_comma=False)

        except Exception as e:
            st.error(f"Redisçµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")


# ==================================================
# ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ç®¡ç†
# ==================================================
class MCPApplication:
    """MCPã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ¡ã‚¤ãƒ³ç®¡ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.status_manager = ServerStatusManager()
        self.sidebar_manager = SidebarManager(self.status_manager)

        # ãƒšãƒ¼ã‚¸å®šç¾©
        self.tab_names = ["ğŸ” ãƒ‡ãƒ¼ã‚¿ç¢ºèª", "ğŸ¤– AI ãƒãƒ£ãƒƒãƒˆ", "ğŸ“Š ç›´æ¥ã‚¯ã‚¨ãƒª", "ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿åˆ†æ", "âš™ï¸ è¨­å®š"]
        self.pages = self._initialize_pages()

    def _initialize_pages(self):
        """ãƒšãƒ¼ã‚¸ã®åˆæœŸåŒ–"""
        try:
            from helper_mcp_pages import DirectQueryPage, SettingsPage
            return {
                0: DataViewPage("ãƒ‡ãƒ¼ã‚¿ç¢ºèª", self.status_manager),
                1: AIChatPage("AIãƒãƒ£ãƒƒãƒˆ", self.status_manager),
                2: DirectQueryPage("ç›´æ¥ã‚¯ã‚¨ãƒª", self.status_manager),
                3: DataAnalysisPage("ãƒ‡ãƒ¼ã‚¿åˆ†æ", self.status_manager),
                4: SettingsPage("è¨­å®š", self.status_manager),
            }
        except ImportError:
            # helper_mcp_pages.py ãŒå­˜åœ¨ã—ãªã„å ´åˆã®ç°¡æ˜“ç‰ˆ
            return {
                0: DataViewPage("ãƒ‡ãƒ¼ã‚¿ç¢ºèª", self.status_manager),
                1: AIChatPage("AIãƒãƒ£ãƒƒãƒˆ", self.status_manager),
                2: None,  # ç°¡æ˜“ç‰ˆã§ã¯æœªå®Ÿè£…
                3: DataAnalysisPage("ãƒ‡ãƒ¼ã‚¿åˆ†æ", self.status_manager),
                4: None,  # ç°¡æ˜“ç‰ˆã§ã¯æœªå®Ÿè£…
            }

    def run(self):
        """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œ"""
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
        MCPSessionManager.init_session()

        # ç’°å¢ƒå¤‰æ•°ã®ç¢ºèªã¨è­¦å‘Šè¡¨ç¤º
        self._check_environment()

        # ã‚µã‚¤ãƒ‰ãƒãƒ¼æç”»
        self.sidebar_manager.render_server_status()
        self.sidebar_manager.render_quick_actions()
        current_tab = self.sidebar_manager.render_navigation(self.tab_names)

        # ç¾åœ¨ã®ãƒšãƒ¼ã‚¸è¡¨ç¤º
        st.markdown(f"### ç¾åœ¨ã®ãƒšãƒ¼ã‚¸: {self.tab_names[current_tab]}")

        # ãƒšãƒ¼ã‚¸ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®æç”»
        if current_tab in self.pages and self.pages[current_tab] is not None:
            self.pages[current_tab].render()
        else:
            st.warning(f"ãƒšãƒ¼ã‚¸ {current_tab} ã¯å®Ÿè£…ä¸­ã§ã™")
            self._render_setup_instructions()

    def _check_environment(self):
        """ç’°å¢ƒè¨­å®šã®ãƒã‚§ãƒƒã‚¯ã¨è­¦å‘Šè¡¨ç¤º"""
        missing_vars = []

        # å¿…è¦ãªç’°å¢ƒå¤‰æ•°ã‚’ãƒã‚§ãƒƒã‚¯
        required_vars = {
            'OPENAI_API_KEY': 'OpenAI APIã‚­ãƒ¼',
            'PG_CONN_STR'   : 'PostgreSQLæ¥ç¶šæ–‡å­—åˆ—'
        }

        for var, description in required_vars.items():
            if not safe_get_secret(var, os.getenv(var)):
                missing_vars.append(f"**{var}**: {description}")

        if missing_vars:
            with st.sidebar.expander("âš ï¸ è¨­å®šä¸å‚™", expanded=True):
                st.warning("ä»¥ä¸‹ã®è¨­å®šãŒä¸è¶³ã—ã¦ã„ã¾ã™:")
                for var in missing_vars:
                    st.write(f"- {var}")

                st.info("è¨­å®šæ–¹æ³•ã¯ã€Œâš™ï¸ è¨­å®šã€ã‚¿ãƒ–ã‚’å‚ç…§ã—ã¦ãã ã•ã„")

    def _render_setup_instructions(self):
        """ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †ã®è¡¨ç¤º"""
        st.markdown("""
        ## ğŸš€ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †

        ### 1. ç’°å¢ƒå¤‰æ•°ã®è¨­å®š
        ä»¥ä¸‹ã®ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¦ãã ã•ã„ï¼š

        ```bash
        # OpenAI API ã‚­ãƒ¼ï¼ˆå¿…é ˆï¼‰
        export OPENAI_API_KEY="sk-..."

        # PostgreSQLæ¥ç¶šæ–‡å­—åˆ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        export PG_CONN_STR="postgresql://user:pass@localhost:5432/dbname"
        ```

        ### 2. Dockerã‚µãƒ¼ãƒ“ã‚¹èµ·å‹•ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        ```bash
        docker-compose -f docker-compose.mcp-demo.yml up -d
        ```

        ### 3. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æŠ•å…¥ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        ```bash
        uv run python scripts/setup_test_data.py
        ```
        """)


# ==================================================
# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
# ==================================================
__all__ = [
    'MCPApplication',
    'MCPSessionManager',
    'ServerStatusManager',
    'RedisManager',
    'PostgreSQLManager',
    'ElasticsearchManager',
    'QdrantManager',
    'SidebarManager',
    'DataViewPage',
    'AIChatPage',
    'DataAnalysisPage',
    'safe_get_secret',
    'safe_format_number',
    'safe_format_metric',
]
