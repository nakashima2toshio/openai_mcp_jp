#!/usr/bin/env python3
"""
MCPãƒ‡ãƒ¼ã‚¿æŠ•å…¥ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
Usage: python data.py [--postgres] [--redis] [--elasticsearch] [--qdrant] [--all]
"""

import os
import sys
import argparse
import psycopg2
import redis
import requests
import json
import random
from datetime import datetime, timedelta
from pathlib import Path


def setup_redis_data():
    """Redisã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®æŠ•å…¥"""
    print("ğŸ”´ Redisãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­...")
    
    redis_url = os.getenv('REDIS_URL', 'redis://localhost:6379/0')
    
    try:
        r = redis.from_url(redis_url, decode_responses=True)
        
        # æ¥ç¶šãƒ†ã‚¹ãƒˆ
        r.ping()
        print("  ğŸ”Œ Redisæ¥ç¶šç¢ºèªå®Œäº†")
        
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢
        r.flushdb()
        print("  ğŸ§¹ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢")
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿
        print("  ğŸ‘¤ ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿æŠ•å…¥ä¸­...")
        sessions = {
            "session:user1": json.dumps({
                "user_id": 1,
                "username": "ç”°ä¸­å¤ªéƒ",
                "last_login": "2024-01-15T10:30:00Z",
                "preferences": {"theme": "dark", "lang": "ja"}
            }),
            "session:user2": json.dumps({
                "user_id": 2,
                "username": "ä½è—¤èŠ±å­",
                "last_login": "2024-01-16T09:15:00Z",
                "preferences": {"theme": "light", "lang": "ja"}
            })
        }
        
        for key, value in sessions.items():
            r.setex(key, 3600, value)  # 1æ™‚é–“ã®TTL
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿
        print("  ğŸ—„ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ãƒ¼ã‚¿æŠ•å…¥ä¸­...")
        cache_data = {
            "cache:products:popular": json.dumps([
                {"id": 1, "name": "ãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³", "sales_count": 150},
                {"id": 2, "name": "ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³", "sales_count": 200},
                {"id": 3, "name": "ãƒ¯ã‚¤ãƒ¤ãƒ¬ã‚¹ã‚¤ãƒ¤ãƒ›ãƒ³", "sales_count": 300}
            ]),
            "cache:stats:daily": json.dumps({
                "total_orders": 45,
                "total_revenue": 125000,
                "active_users": 23,
                "date": "2024-01-16"
            })
        }
        
        for key, value in cache_data.items():
            r.setex(key, 1800, value)  # 30åˆ†ã®TTL
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒªã‚¹ãƒˆï¼‰
        print("  ğŸ“Š ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿æŠ•å…¥ä¸­...")
        recent_orders = [
            json.dumps({"order_id": 101, "customer": "ç”°ä¸­å¤ªéƒ", "amount": 15800, "time": "10:30"}),
            json.dumps({"order_id": 102, "customer": "ä½è—¤èŠ±å­", "amount": 8900, "time": "10:45"}),
            json.dumps({"order_id": 103, "customer": "éˆ´æœ¨ä¸€éƒ", "amount": 12500, "time": "11:00"})
        ]
        
        for order in recent_orders:
            r.lpush("orders:recent", order)
        r.ltrim("orders:recent", 0, 99)  # æœ€æ–°100ä»¶ã®ã¿ä¿æŒ
        
        # ã‚«ã‚¦ãƒ³ã‚¿
        print("  ğŸ”¢ ã‚«ã‚¦ãƒ³ã‚¿ãƒ‡ãƒ¼ã‚¿æŠ•å…¥ä¸­...")
        counters = {
            "counter:page_views": 1250,
            "counter:api_calls": 890,
            "counter:user_registrations": 156
        }
        
        for key, value in counters.items():
            r.set(key, value)
        
        # çµæœç¢ºèª
        total_keys = r.dbsize()
        print(f"  âœ… Redis: {total_keys}å€‹ã®ã‚­ãƒ¼ã‚’æŠ•å…¥")
        return True
        
    except Exception as e:
        print(f"  âŒ Redis ã‚¨ãƒ©ãƒ¼: {e}")
        return False


def setup_postgresql_data():
    """PostgreSQLãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æŠ•å…¥"""
    print("ğŸ˜ PostgreSQLãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­...")
    
    conn_str = os.getenv('PG_CONN_STR', 'postgresql://testuser:testpass@localhost:5432/testdb')
    
    try:
        conn = psycopg2.connect(conn_str)
        cursor = conn.cursor()
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
        print("  ğŸ“‹ ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆä¸­...")
        cursor.execute("""
        DROP TABLE IF EXISTS orders CASCADE;
        DROP TABLE IF EXISTS customers CASCADE;
        DROP TABLE IF EXISTS products CASCADE;
        
        CREATE TABLE customers (
            id SERIAL PRIMARY KEY,
            name VARCHAR(100) NOT NULL,
            email VARCHAR(100) UNIQUE NOT NULL,
            age INTEGER,
            city VARCHAR(50) NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
        
        CREATE TABLE products (
            id SERIAL PRIMARY KEY,
            name VARCHAR(100) NOT NULL,
            category VARCHAR(50) NOT NULL,
            price DECIMAL(10,2) NOT NULL,
            stock_quantity INTEGER NOT NULL DEFAULT 0,
            description TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
        
        CREATE TABLE orders (
            id SERIAL PRIMARY KEY,
            customer_id INTEGER REFERENCES customers(id),
            product_name VARCHAR(100) NOT NULL,
            quantity INTEGER NOT NULL,
            price DECIMAL(10,2) NOT NULL,
            order_date DATE NOT NULL DEFAULT CURRENT_DATE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
        """)
        
        # é¡§å®¢ãƒ‡ãƒ¼ã‚¿æŠ•å…¥
        print("  ğŸ‘¥ é¡§å®¢ãƒ‡ãƒ¼ã‚¿æŠ•å…¥ä¸­...")
        customers = [
            ('ç”°ä¸­å¤ªéƒ', 'tanaka@example.com', 32, 'æ±äº¬'),
            ('ä½è—¤èŠ±å­', 'sato@example.com', 28, 'å¤§é˜ª'),
            ('éˆ´æœ¨ä¸€éƒ', 'suzuki@example.com', 45, 'åå¤å±‹'),
            ('é«˜æ©‹ç¾å’²', 'takahashi@example.com', 24, 'æ±äº¬'),
            ('æ¸¡è¾ºå¥å¤ª', 'watanabe@example.com', 38, 'ç¦å²¡'),
            ('å±±ç”°ç”±ç¾', 'yamada@example.com', 31, 'æœ­å¹Œ'),
            ('ä¸­æ‘å¤§è¼”', 'nakamura@example.com', 41, 'æ±äº¬'),
            ('å°æ—ã•ãã‚‰', 'kobayashi@example.com', 27, 'å¤§é˜ª'),
            ('åŠ è—¤æ­£é›„', 'kato@example.com', 52, 'åå¤å±‹'),
            ('å‰ç”°éº»è¡£', 'yoshida@example.com', 29, 'æ¨ªæµœ')
        ]
        
        for name, email, age, city in customers:
            cursor.execute("""
            INSERT INTO customers (name, email, age, city) 
            VALUES (%s, %s, %s, %s)
            """, (name, email, age, city))
        
        # å•†å“ãƒ‡ãƒ¼ã‚¿æŠ•å…¥
        print("  ğŸ›ï¸ å•†å“ãƒ‡ãƒ¼ã‚¿æŠ•å…¥ä¸­...")
        products = [
            ('ãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³', 'ã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹', 89800, 50, 'é«˜æ€§èƒ½ãªãƒ“ã‚¸ãƒã‚¹å‘ã‘ãƒãƒ¼ãƒˆãƒ‘ã‚½ã‚³ãƒ³'),
            ('ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³', 'ã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹', 79800, 100, 'æœ€æ–°ã®Androidã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³'),
            ('ãƒ¯ã‚¤ãƒ¤ãƒ¬ã‚¹ã‚¤ãƒ¤ãƒ›ãƒ³', 'ã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹', 15800, 200, 'ãƒã‚¤ã‚ºã‚­ãƒ£ãƒ³ã‚»ãƒªãƒ³ã‚°æ©Ÿèƒ½ä»˜ã'),
            ('ã‚³ãƒ¼ãƒ’ãƒ¼ãƒ¡ãƒ¼ã‚«ãƒ¼', 'ã‚­ãƒƒãƒãƒ³å®¶é›»', 12800, 30, 'è‡ªå‹•ãƒ‰ãƒªãƒƒãƒ—å¼ã‚³ãƒ¼ãƒ’ãƒ¼ãƒ¡ãƒ¼ã‚«ãƒ¼'),
            ('é›»å­ãƒ¬ãƒ³ã‚¸', 'ã‚­ãƒƒãƒãƒ³å®¶é›»', 19800, 25, 'å¤šæ©Ÿèƒ½é›»å­ãƒ¬ãƒ³ã‚¸'),
            ('æƒé™¤æ©Ÿ', 'ã‚­ãƒƒãƒãƒ³å®¶é›»', 28800, 40, 'ã‚µã‚¤ã‚¯ãƒ­ãƒ³å¼æƒé™¤æ©Ÿ'),
            ('Tã‚·ãƒ£ãƒ„', 'ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³', 2980, 500, 'ã‚³ãƒƒãƒˆãƒ³100%ã®Tã‚·ãƒ£ãƒ„'),
            ('ã‚¸ãƒ¼ãƒ³ã‚º', 'ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³', 7980, 200, 'ã‚¹ãƒˆãƒ¬ãƒƒãƒç´ æã®ã‚¸ãƒ¼ãƒ³ã‚º'),
            ('ã‚¹ãƒ‹ãƒ¼ã‚«ãƒ¼', 'ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³', 8980, 150, 'ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ã‚¹ãƒ‹ãƒ¼ã‚«ãƒ¼'),
            ('ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚·ãƒ¥ãƒ¼ã‚º', 'ã‚¹ãƒãƒ¼ãƒ„', 12800, 80, 'è»½é‡ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚·ãƒ¥ãƒ¼ã‚º')
        ]
        
        for name, category, price, stock, description in products:
            cursor.execute("""
            INSERT INTO products (name, category, price, stock_quantity, description) 
            VALUES (%s, %s, %s, %s, %s)
            """, (name, category, price, stock, description))
        
        # æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿æŠ•å…¥
        print("  ğŸ“¦ æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿æŠ•å…¥ä¸­...")
        cursor.execute("SELECT id FROM customers")
        customer_ids = [row[0] for row in cursor.fetchall()]
        
        cursor.execute("SELECT name, price FROM products")
        products_data = cursor.fetchall()
        
        orders = []
        start_date = datetime.now() - timedelta(days=90)
        
        for _ in range(100):
            customer_id = random.choice(customer_ids)
            product_name, price = random.choice(products_data)
            quantity = random.randint(1, 5)
            order_date = start_date + timedelta(days=random.randint(0, 90))
            orders.append((customer_id, product_name, quantity, price, order_date.date()))
        
        for order in orders:
            cursor.execute("""
            INSERT INTO orders (customer_id, product_name, quantity, price, order_date) 
            VALUES (%s, %s, %s, %s, %s)
            """, order)
        
        conn.commit()
        
        # çµæœç¢ºèª
        cursor.execute("SELECT COUNT(*) FROM customers")
        customer_count = cursor.fetchone()[0]
        cursor.execute("SELECT COUNT(*) FROM products") 
        product_count = cursor.fetchone()[0]
        cursor.execute("SELECT COUNT(*) FROM orders")
        order_count = cursor.fetchone()[0]
        
        print(f"  âœ… PostgreSQL: é¡§å®¢{customer_count}ä»¶ã€å•†å“{product_count}ä»¶ã€æ³¨æ–‡{order_count}ä»¶")
        conn.close()
        return True
        
    except Exception as e:
        print(f"  âŒ PostgreSQL ã‚¨ãƒ©ãƒ¼: {e}")
        return False


def setup_elasticsearch_data():
    """Elasticsearchã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®æŠ•å…¥"""
    print("ğŸ” Elasticsearchãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­...")
    
    es_url = os.getenv('ELASTIC_URL', 'http://localhost:9200')
    
    try:
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
        index_config = {
            "mappings": {
                "properties": {
                    "title": {"type": "text", "analyzer": "standard"},
                    "content": {"type": "text", "analyzer": "standard"}, 
                    "category": {"type": "keyword"},
                    "author": {"type": "keyword"},
                    "published_date": {"type": "date"},
                    "view_count": {"type": "integer"},
                    "tags": {"type": "keyword"}
                }
            }
        }
        
        response = requests.put(f"{es_url}/blog_articles", json=index_config)
        print(f"  ğŸ“‹ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ: {response.status_code}")
        
        # ã‚µãƒ³ãƒ—ãƒ«è¨˜äº‹ãƒ‡ãƒ¼ã‚¿
        articles = [
            {
                "title": "Pythonãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°å…¥é–€",
                "content": "Pythonã¯åˆå¿ƒè€…ã«ã‚‚å­¦ã³ã‚„ã™ã„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§ã™ã€‚æ–‡æ³•ãŒã‚·ãƒ³ãƒ—ãƒ«ã§ã€è±Šå¯Œãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒç‰¹å¾´ã§ã™ã€‚",
                "category": "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°",
                "author": "ç”°ä¸­å¤ªéƒ", 
                "published_date": "2024-01-15",
                "view_count": 1250,
                "tags": ["Python", "å…¥é–€", "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°"]
            },
            {
                "title": "æ©Ÿæ¢°å­¦ç¿’ã®åŸºç¤",
                "content": "æ©Ÿæ¢°å­¦ç¿’ã¯äººå·¥çŸ¥èƒ½ã®ä¸€åˆ†é‡ã§ã€ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹æŠ€è¡“ã§ã™ã€‚",
                "category": "AIãƒ»æ©Ÿæ¢°å­¦ç¿’",
                "author": "ä½è—¤èŠ±å­",
                "published_date": "2024-01-20", 
                "view_count": 890,
                "tags": ["æ©Ÿæ¢°å­¦ç¿’", "AI", "ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹"]
            },
            {
                "title": "Dockerå…¥é–€ã‚¬ã‚¤ãƒ‰",
                "content": "Dockerã¯ã‚³ãƒ³ãƒ†ãƒŠæŠ€è¡“ã‚’ä½¿ã£ã¦ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åŠ¹ç‡çš„ã«ãƒ‡ãƒ—ãƒ­ã‚¤ã§ãã‚‹ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚",
                "category": "ã‚¤ãƒ³ãƒ•ãƒ©",
                "author": "å±±ç”°æ¬¡éƒ",
                "published_date": "2024-01-25",
                "view_count": 650, 
                "tags": ["Docker", "ã‚³ãƒ³ãƒ†ãƒŠ", "DevOps"]
            },
            {
                "title": "Streamlitã§ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä½œæˆ",
                "content": "Streamlitã‚’ä½¿ã†ã¨ç°¡å˜ã«Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚„ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚’ä½œæˆã§ãã¾ã™ã€‚",
                "category": "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°",
                "author": "éˆ´æœ¨ä¸‰éƒ",
                "published_date": "2024-02-01",
                "view_count": 430,
                "tags": ["Streamlit", "Python", "ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰"]
            },
            {
                "title": "Elasticsearchã¨Kibanaã§åˆ†æ", 
                "content": "Elasticsearchã¨Kibanaã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§å¼·åŠ›ãªãƒ‡ãƒ¼ã‚¿åˆ†æç’°å¢ƒã‚’æ§‹ç¯‰ã§ãã¾ã™ã€‚",
                "category": "ãƒ‡ãƒ¼ã‚¿åˆ†æ",
                "author": "é«˜æ©‹å››éƒ",
                "published_date": "2024-02-05",
                "view_count": 720,
                "tags": ["Elasticsearch", "Kibana", "ãƒ‡ãƒ¼ã‚¿åˆ†æ"]
            }
        ]
        
        # ãƒ‡ãƒ¼ã‚¿æŠ•å…¥
        for i, article in enumerate(articles, 1):
            response = requests.post(f"{es_url}/blog_articles/_doc/{i}", json=article)
            print(f"  ğŸ“„ è¨˜äº‹{i}: {response.status_code}")
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥
        requests.post(f"{es_url}/blog_articles/_refresh")
        print(f"  âœ… Elasticsearch: {len(articles)}ä»¶ã®è¨˜äº‹ã‚’æŠ•å…¥")
        return True
        
    except Exception as e:
        print(f"  âŒ Elasticsearch ã‚¨ãƒ©ãƒ¼: {e}")
        return False


def setup_qdrant_data():
    """Qdrantãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã®æŠ•å…¥"""
    print("ğŸ¯ Qdrantãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­...")
    
    qdrant_url = os.getenv('QDRANT_URL', 'http://localhost:6333')
    
    try:
        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆ
        collection_config = {
            "vectors": {
                "size": 384,
                "distance": "Cosine"
            }
        }
        
        response = requests.put(f"{qdrant_url}/collections/product_embeddings", json=collection_config)
        print(f"  ğŸ“‹ ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆ: {response.status_code}")
        
        # ã‚µãƒ³ãƒ—ãƒ«å•†å“ãƒ‡ãƒ¼ã‚¿
        products = [
            {
                "id": 1,
                "payload": {
                    "name": "ãƒ¯ã‚¤ãƒ¤ãƒ¬ã‚¹ãƒ˜ãƒƒãƒ‰ãƒ›ãƒ³",
                    "description": "é«˜éŸ³è³ªã®Bluetoothãƒ¯ã‚¤ãƒ¤ãƒ¬ã‚¹ãƒ˜ãƒƒãƒ‰ãƒ›ãƒ³ã€‚ãƒã‚¤ã‚ºã‚­ãƒ£ãƒ³ã‚»ãƒªãƒ³ã‚°æ©Ÿèƒ½ä»˜ãã€‚",
                    "category": "ã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹", 
                    "price": 15800,
                    "brand": "TechSound"
                },
                "vector": [random.uniform(-1, 1) for _ in range(384)]
            },
            {
                "id": 2,
                "payload": {
                    "name": "ã‚³ãƒ¼ãƒ’ãƒ¼ãƒ¡ãƒ¼ã‚«ãƒ¼",
                    "description": "è‡ªå‹•ãƒ‰ãƒªãƒƒãƒ—å¼ã‚³ãƒ¼ãƒ’ãƒ¼ãƒ¡ãƒ¼ã‚«ãƒ¼ã€‚ã‚¿ã‚¤ãƒãƒ¼æ©Ÿèƒ½ä»˜ãã§æœã®æº–å‚™ãŒæ¥½ã«ã€‚",
                    "category": "ã‚­ãƒƒãƒãƒ³å®¶é›»",
                    "price": 8900,
                    "brand": "BrewMaster"
                },
                "vector": [random.uniform(-1, 1) for _ in range(384)]
            },
            {
                "id": 3,
                "payload": {
                    "name": "ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚·ãƒ¥ãƒ¼ã‚º", 
                    "description": "è»½é‡ã§é€šæ°—æ€§ã®è‰¯ã„ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚·ãƒ¥ãƒ¼ã‚ºã€‚é•·è·é›¢èµ°ã«æœ€é©ã€‚",
                    "category": "ã‚¹ãƒãƒ¼ãƒ„",
                    "price": 12500,
                    "brand": "RunFast"
                },
                "vector": [random.uniform(-1, 1) for _ in range(384)]
            },
            {
                "id": 4,
                "payload": {
                    "name": "ãƒ“ã‚¸ãƒã‚¹ãƒãƒƒã‚°",
                    "description": "è€ä¹…æ€§ã®é«˜ã„ãƒŠã‚¤ãƒ­ãƒ³è£½ãƒ“ã‚¸ãƒã‚¹ãƒãƒƒã‚°ã€‚PCåç´ã‚¹ãƒšãƒ¼ã‚¹ä»˜ãã€‚",
                    "category": "ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³",
                    "price": 6800,
                    "brand": "ProBag"
                },
                "vector": [random.uniform(-1, 1) for _ in range(384)]
            },
            {
                "id": 5,
                "payload": {
                    "name": "ã‚¹ãƒãƒ¼ãƒˆã‚¦ã‚©ãƒƒãƒ",
                    "description": "å¥åº·ç®¡ç†æ©Ÿèƒ½ä»˜ãã‚¹ãƒãƒ¼ãƒˆã‚¦ã‚©ãƒƒãƒã€‚å¿ƒæ‹æ•°ã‚„æ­©æ•°ã‚’æ¸¬å®šã€‚",
                    "category": "ã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹",
                    "price": 22000,
                    "brand": "HealthTech"
                },
                "vector": [random.uniform(-1, 1) for _ in range(384)]
            }
        ]
        
        # ãƒ‡ãƒ¼ã‚¿æŠ•å…¥
        points_data = {"points": products}
        response = requests.put(f"{qdrant_url}/collections/product_embeddings/points", json=points_data)
        print(f"  ğŸ¯ ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿æŠ•å…¥: {response.status_code}")
        print(f"  âœ… Qdrant: {len(products)}ä»¶ã®ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’æŠ•å…¥")
        return True
        
    except Exception as e:
        print(f"  âŒ Qdrant ã‚¨ãƒ©ãƒ¼: {e}")
        return False


def main():
    parser = argparse.ArgumentParser(description="MCPãƒ‡ãƒ¼ã‚¿æŠ•å…¥")
    parser.add_argument("--postgres", action="store_true", help="PostgreSQLãƒ‡ãƒ¼ã‚¿ã®ã¿æŠ•å…¥")
    parser.add_argument("--redis", action="store_true", help="Redisãƒ‡ãƒ¼ã‚¿ã®ã¿æŠ•å…¥")
    parser.add_argument("--elasticsearch", action="store_true", help="Elasticsearchãƒ‡ãƒ¼ã‚¿ã®ã¿æŠ•å…¥")
    parser.add_argument("--qdrant", action="store_true", help="Qdrantãƒ‡ãƒ¼ã‚¿ã®ã¿æŠ•å…¥")
    parser.add_argument("--all", action="store_true", help="å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ•å…¥")
    args = parser.parse_args()
    
    # å¼•æ•°ãŒãªã„å ´åˆã¯å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ•å…¥
    if not any([args.postgres, args.redis, args.elasticsearch, args.qdrant, args.all]):
        args.all = True
    
    print("ğŸš€ MCPãƒ‡ãƒ¼ã‚¿æŠ•å…¥ã‚’é–‹å§‹ã—ã¾ã™")
    print("=" * 50)
    
    success_count = 0
    total_count = 0
    
    if args.postgres or args.all:
        total_count += 1
        if setup_postgresql_data():
            success_count += 1
    
    if args.redis or args.all:
        total_count += 1
        if setup_redis_data():
            success_count += 1
    
    if args.elasticsearch or args.all:
        total_count += 1
        if setup_elasticsearch_data():
            success_count += 1
    
    if args.qdrant or args.all:
        total_count += 1
        if setup_qdrant_data():
            success_count += 1
    
    print("\n" + "=" * 50)
    print(f"ğŸ“Š çµæœ: {success_count}/{total_count} ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãƒ‡ãƒ¼ã‚¿ã‚’æŠ•å…¥å®Œäº†")
    
    if success_count == total_count:
        print("ğŸ‰ å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿æŠ•å…¥ãŒæˆåŠŸã—ã¾ã—ãŸ!")
        print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("1. ã‚µãƒ¼ãƒãƒ¼èµ·å‹•: python server.py")
        print("2. ã‚¢ãƒ—ãƒªèµ·å‹•: streamlit run mcp_db_show_data.py")
    else:
        print("âš ï¸ ä¸€éƒ¨ã®ãƒ‡ãƒ¼ã‚¿æŠ•å…¥ã«å¤±æ•—ã—ã¾ã—ãŸ")
        print("Dockerã‚µãƒ¼ãƒ“ã‚¹ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„:")
        print("docker-compose -f docker-compose/docker-compose.mcp-demo.yml up -d")


if __name__ == "__main__":
    main()